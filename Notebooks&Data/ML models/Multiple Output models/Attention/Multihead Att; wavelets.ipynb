{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed254beb-b30d-40dd-b1ab-1675290adaa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multihead Attention; wavelets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e502d-6092-4e20-b503-48751d61133d",
   "metadata": {},
   "source": [
    "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef10ad-0b50-4f6a-a136-5d36e02694ce",
   "metadata": {},
   "source": [
    "Lets test multiple attention heads, one for each input, with univariate and mutivariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e6d16-e776-4783-b67a-52225291163c",
   "metadata": {},
   "source": [
    "Lets test wavelet threshold denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9670ec-6b1b-4710-b68c-6353db090f60",
   "metadata": {},
   "source": [
    "Due to a slip in the matrix profile function, the matrix profile was computed in reverse, this is adressed and computed normally in the 'Multihead Att_fwd; wavelets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cf8a4-056b-49a8-8123-cc15d8f2f71b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2243fdcb-c389-4556-be27-9373234fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import MultiHeadAttention, BatchNormalization, LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pywt\n",
    "import matrixprofile as mp\n",
    "from keras import Model\n",
    "from keras.layers import dot\n",
    "import datetime \n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd68e3ae-22e3-43af-b5e2-abdca3c87420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead):\n",
    "    X, y = list(), list()\n",
    "    example_count = int((len(sequence)/step_interval))\n",
    "    for i in range(example_count):\n",
    "        # find the end of this pattern\n",
    "        end_ix = (i*step_interval) + n_steps_in\n",
    "        out_start_ix = end_ix + n_step_lookahead -1\n",
    "        out_end_ix = end_ix + n_steps_out + n_step_lookahead -1\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[(i*step_interval):end_ix], sequence[out_start_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479cb03e-33f8-4df8-afe6-82b2351713ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6],\n",
       "        [3, 4, 5, 6, 7]]),\n",
       " array([[ 9],\n",
       "        [10],\n",
       "        [11],\n",
       "        [12]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To demonstrate above function\n",
    "sequence = range(0,13)\n",
    "n_steps_in = 1\n",
    "n_steps_in = 5\n",
    "n_steps_out =1\n",
    "step_interval =1\n",
    "n_step_lookahead=5\n",
    "split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0113c1-d102-4605-9fc3-542f00bd488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_data = pd.read_csv (r'C:\\Users/conal/Desktop/MCM/Practicum - Copy/data/block gas price percentile data.csv', header=0)\n",
    "percentile_data['datetime'] = pd.to_datetime(percentile_data['block_timestamp'], format = '%Y-%m-%d %H:%M:%S UTC')\n",
    "\n",
    "percentile_data = percentile_data.sort_values(by='datetime',ascending=False)\n",
    "percentile_data = percentile_data.set_index('datetime')\n",
    "percentile_data = percentile_data.resample('5T').mean()\n",
    "percentile_data = percentile_data/1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a6b649-6d02-4b5c-8892-6ca97fa10813",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum - Copy\\data\\ETH,gas,usage merged 11-26 to 05-26.csv', header=0)\n",
    "usage_data['datetime'] = pd.to_datetime(usage_data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "usage_data = usage_data.set_index('datetime')\n",
    "\n",
    "usage_data = usage_data.squeeze()\n",
    "usage_data = usage_data.astype('float')\n",
    "usage_data = usage_data.resample('5T').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49359adb-72a2-4d36-92a3-160ae229ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_data2 = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum - Copy\\data\\Contract counts 2021-11-26 to 2022-05-26.csv', header=0, index_col=0)\n",
    "usage_data2['datetime'] = pd.to_datetime(usage_data2['block_timestamp'], format = '%Y-%m-%d %H:%M:%S') \n",
    "usage_data2 = usage_data2.set_index('datetime')\n",
    "usage_data2 = usage_data2.drop(['block_timestamp'], axis=1)\n",
    "usage_data2 = usage_data2.squeeze()\n",
    "usage_data2 = usage_data2.astype('float')\n",
    "usage_data2 = usage_data2.resample('5T').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8901dad6-24e3-4393-bce8-03d4ff7aa1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = usage_data.merge(percentile_data, left_index=True, right_index=True)\n",
    "data = data.merge(usage_data2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123a9bf",
   "metadata": {},
   "source": [
    "Load data, datetime to index, downsample with left edge label, convert wei to gwei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac449a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples(data):\n",
    " \n",
    "    #Filter inputs, standardize\n",
    "    data =data[inputs]\n",
    "    scaler = StandardScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    \n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], len(inputs)))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], len(inputs)))\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046086f6-7346-4550-8d58-ba108d69ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, activation='tanh', input_shape=(n_steps_in, len(inputs))))\n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    model.add(LSTM(100, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(len(inputs))))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5878928-c13c-4766-bcfe-2a6d1de3a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1251aaea-8a1b-423a-80c4-d88e601b2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics(yhat, y_val2):\n",
    "    #We will use validation data that has not had outleirs limited, will be a different min/max scaler as such\n",
    "    dict_indexes=[]\n",
    "    dict_dfs=[]\n",
    "    for j in range(0, n_steps_out):\n",
    "        RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "        for i in range(0, len(inputs)):  \n",
    "            pred_descaled= (scaler.inverse_transform(yhat[:,j:j+1,:].reshape(yhat.shape[0], yhat.shape[2])))[:, i:i+1]\n",
    "            groud_truth_descaled= ((scaler2.inverse_transform(y_val2[:,j:j+1,:].reshape(y_val2.shape[0], y_val2.shape[2]))))[:, i:i+1]\n",
    "            RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "            MSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=True)\n",
    "            MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "            MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "            R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "            RMSE_list.append(RMSE)\n",
    "            MAE_list.append(MAE)\n",
    "            MAPE_list.append(MAPE)\n",
    "            R2_list.append(R2)\n",
    "            MSE_list.append(MSE)\n",
    "        metrics_df = pd.DataFrame({'RMSE':RMSE_list, 'MSE':MSE_list, 'MAE':MAE_list, 'MAPE':MAPE_list, 'R2':R2_list}, index=inputs)\n",
    "        dict_dfs.append(metrics_df)\n",
    "        dict_indexes.append('Lookahead' +str(j))\n",
    "    metrics_dict = dict(zip(dict_indexes, dict_dfs))\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b29778f2-615e-4fca-878d-a1f3f4c7b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples_univariate_output(data):\n",
    " \n",
    "    #Filter inputs, standardize\n",
    "    data =data[inputs]\n",
    "    scaler = StandardScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    \n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    \n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM, filter output to only the first input\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], len(inputs)))[:,:,:1]\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], len(inputs)))[:,:,:1]\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a382560-4bf0-4dac-bc61-eb8cebeaafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics_univariate_y(yhat, y_val2):\n",
    "    #reverts standard scaling, returns dictionary of metrics for single output, for all lookaheads\n",
    "    dict_indexes=[]\n",
    "    dict_dfs=[]\n",
    "    RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "    yhat_stretched= np.repeat(yhat[:,:,0],len(inputs)).reshape(yhat.shape[0], yhat.shape[1], len(inputs))\n",
    "    y_val2_stretched= np.repeat(y_val2[:,:,0],len(inputs)).reshape(y_val2.shape[0], y_val2.shape[1], len(inputs))\n",
    "    \n",
    "    for j in range(0, n_steps_out):\n",
    "        \n",
    "        \n",
    "        pred_descaled= (scaler.inverse_transform(yhat_stretched[:, j:j+1, :].reshape(yhat_stretched.shape[0], yhat_stretched.shape[2])))[:,:1]\n",
    "        groud_truth_descaled= (scaler.inverse_transform(array([y_val2[ :, j:j+1,0].reshape(y_val2.shape[0])]*len(inputs)).transpose()))[:,:1]\n",
    "        RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "        MSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=True)\n",
    "        MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "        MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "        R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "        RMSE_list.append(RMSE)\n",
    "        MAE_list.append(MAE)\n",
    "        MAPE_list.append(MAPE)\n",
    "        R2_list.append(R2)\n",
    "        MSE_list.append(MSE)\n",
    "    metrics_df = pd.DataFrame({'RMSE':RMSE_list, 'MSE':MSE_list, 'MAE':MAE_list, 'MAPE':MAPE_list, 'R2':R2_list}, index=range(1, (n_steps_out+1)))\n",
    "\n",
    " \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6169681-82c4-4bfc-8339-abd4f990ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mp_reversed(data, window):\n",
    "    #Given 3d array, add matrix profile of (x,y,0) as new dimension; new array has dimensiosn (x,y,z+1) \n",
    "    mp_list=[]\n",
    "    for i in data[:,:,0]:\n",
    "        profile = mp.compute(np.flip(i, axis=0), window, n_jobs=4)['mp']\n",
    "        #we are padding the end of the sequence with the mean\n",
    "        #matrix profile is always 1 full window size smalelr than input data\n",
    "        mp_list.append(np.append(profile,([mean(profile)]*(data.shape[1]-len(profile)))))\n",
    "        \n",
    "    #concatenate matrix profile data with original    \n",
    "    mp_array = np.array(mp_list).reshape(data.shape[0], data.shape[1])\n",
    "    std_array = ((mp_array-mean(mp_array))/np.std(mp_array)).reshape(data.shape[0], data.shape[1],1)\n",
    "    data = np.concatenate((data, std_array), axis=2)[:, window:, :]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d667540-d94b-41e2-8be2-2157d8e1d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def madev(d, axis=None):\n",
    "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b0438e-807a-4952-b5c7-1b29b1dec841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoising(x, wavelet='db4', level=2, tmod=1):\n",
    "    \n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/tmod) * madev(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt(3 * np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "    return pywt.waverec(coeff, wavelet, mode='per')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d12899c2-ed58-4ebc-9a50-3471eefa885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_array(data, variable, wavelet, level, tmod):\n",
    "    denoised_examples=[]\n",
    "    for i in (data[:,:,variable]):\n",
    "        \n",
    "        denoised_examples.append(wavelet_denoising(i, wavelet=wavelet, level=level, tmod=tmod))\n",
    "        denoised_array= np.array(denoised_examples)\n",
    "        denoised_array= denoised_array.reshape(denoised_array.shape[0], denoised_array.shape[1], 1)\n",
    "    return np.concatenate((denoised_array, data[:,:,1:]),axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f4690-95e3-46ee-8934-be402e8cb94a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 layer, all variables, MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44cd8891-6f7d-4b41-9ac8-09b37e247d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(): \n",
    "    \n",
    "    #set up callback for best val loss model\n",
    "    checkpoint_filepath='./cnn/checkpoint'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    \n",
    "    n_hidden = 30\n",
    "    input_train = Input(shape=(n_steps_in, X_train.shape[2]),name='input')\n",
    "    output_train = Input(shape=( y_train.shape[1], y_train.shape[2]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    enc_head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(\n",
    "            n_hidden, activation='tanh', dropout=0.2, \n",
    "            return_state=True, return_sequences=True,name=('encoder' +str(i)))(input_train)\n",
    "\n",
    "        decoder_input = RepeatVector(y_train.shape[1], name='repeat_vector'+str(i))(encoder_last_h)\n",
    "        decoder_stack_h = LSTM(n_hidden, activation='tanh', dropout=0.2,\n",
    "         return_state=False, return_sequences=True,name=('alignment_model'+str(i)))(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "        attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2], name=('attention_dot'+str(i)))\n",
    "        attention = Activation('softmax', name='attention_activation'+str(i))(attention)\n",
    "        context = dot([attention, encoder_stack_h], axes=[2,1],name='Context'+str(i))\n",
    "        enc_head_list.append(context)\n",
    "    enc_concat_attention = Concatenate(axis=2)(enc_head_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dec_head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(\n",
    "            n_hidden, activation='tanh', dropout=0.2, \n",
    "            return_state=True, return_sequences=True,name=('decoder' +str(i)))(enc_concat_attention)\n",
    "\n",
    "        decoder_input = RepeatVector(y_train.shape[1],name='dec_repeat_vector'+str(i))(encoder_last_h)\n",
    "        decoder_stack_h = LSTM(n_hidden, activation='tanh', dropout=0.2,\n",
    "         return_state=False, return_sequences=True,name=('dec_alignment_model'+str(i)))(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "        attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2], name=('dec_attention_dot'+str(i)))\n",
    "        attention = Activation('softmax', name='dec_attention_activation'+str(i))(attention)\n",
    "        context = dot([attention, encoder_stack_h], axes=[2,1],name='dec_Context'+str(i))\n",
    "        dec_head_list.append(context)\n",
    "    dec_concat_attention = Concatenate(axis=2)(dec_head_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = TimeDistributed(Dense(y_train.shape[2]))(dec_concat_attention)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = TimeDistributed(Dense(y_train.shape[2]))(dec_concat_attention)\n",
    "\n",
    "    model = Model(inputs=input_train, outputs=out)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mae'])\n",
    "    return model, model_checkpoint_callback, checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f294b-8d0d-4dcc-a969-dd367e7620e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 240s 2s/step - loss: 0.2764 - mae: 0.2668 - val_loss: 0.0539 - val_mae: 0.1521\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 154s 2s/step - loss: 0.2268 - mae: 0.2150 - val_loss: 0.0505 - val_mae: 0.1393\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 153s 2s/step - loss: 0.2236 - mae: 0.2178 - val_loss: 0.0480 - val_mae: 0.1379\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 153s 2s/step - loss: 0.2147 - mae: 0.2096 - val_loss: 0.0513 - val_mae: 0.1409\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 164s 2s/step - loss: 0.2085 - mae: 0.2049 - val_loss: 0.0533 - val_mae: 0.1456\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 170s 2s/step - loss: 0.2049 - mae: 0.2040 - val_loss: 0.0509 - val_mae: 0.1388\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 160s 2s/step - loss: 0.2028 - mae: 0.1992 - val_loss: 0.0522 - val_mae: 0.1456\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 154s 2s/step - loss: 0.1995 - mae: 0.2015 - val_loss: 0.0566 - val_mae: 0.1540\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 146s 1s/step - loss: 0.1949 - mae: 0.1962 - val_loss: 0.0673 - val_mae: 0.1757\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 142s 1s/step - loss: 0.1932 - mae: 0.1967 - val_loss: 0.0714 - val_mae: 0.1767\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 142s 1s/step - loss: 0.1925 - mae: 0.1956 - val_loss: 0.0705 - val_mae: 0.1758\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 141s 1s/step - loss: 0.1880 - mae: 0.1926 - val_loss: 0.0645 - val_mae: 0.1653\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 141s 1s/step - loss: 0.1866 - mae: 0.1900 - val_loss: 0.0538 - val_mae: 0.1509\n",
      "Epoch 14/15\n",
      "  9/101 [=>............................] - ETA: 1:41 - loss: 0.3172 - mae: 0.2082"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=288\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0, 1, 2, 3, 4]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    X_train= denoise_array(X_train, 0, 'db4', 2, 3)\n",
    "    X_val= denoise_array(X_val, 0, 'db4', 2, 3)\n",
    "    X_train = add_mp_reversed(X_train, mp_window)\n",
    "    X_val = add_mp_reversed(X_val, mp_window)\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_wavelet1/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_wavelet1/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_wavelet1/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_wavelet1/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_wavelet1/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88dde74c-481e-4b26-a8cf-252a4c8d7720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "\n",
    "\n",
    "for month in [0]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    X_train_D= denoise_array(X_train, 0, 'db4', 2, 3)\n",
    "    X_val_D= denoise_array(X_val, 0, 'db4', 2, 3)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae002a-b38a-411b-b2ce-f3ece1c4ea36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MAE loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e782ec02-aa33-46e3-8297-963880649136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(): \n",
    "    \n",
    "    #set up callback for best val loss model\n",
    "    checkpoint_filepath='./cnn/checkpoint'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    \n",
    "    n_hidden = 30\n",
    "    input_train = Input(shape=(n_steps_in, X_train.shape[2]),name='input')\n",
    "    output_train = Input(shape=( y_train.shape[1], y_train.shape[2]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    enc_head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(\n",
    "            n_hidden, activation='tanh', dropout=0.2, \n",
    "            return_state=True, return_sequences=True,name=('encoder' +str(i)))(input_train)\n",
    "\n",
    "        decoder_input = RepeatVector(y_train.shape[1], name='repeat_vector'+str(i))(encoder_last_h)\n",
    "        decoder_stack_h = LSTM(n_hidden, activation='tanh', dropout=0.2,\n",
    "         return_state=False, return_sequences=True,name=('alignment_model'+str(i)))(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "        attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2], name=('attention_dot'+str(i)))\n",
    "        attention = Activation('softmax', name='attention_activation'+str(i))(attention)\n",
    "        context = dot([attention, encoder_stack_h], axes=[2,1],name='Context'+str(i))\n",
    "        enc_head_list.append(context)\n",
    "    enc_concat_attention = Concatenate(axis=2)(enc_head_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dec_head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(\n",
    "            n_hidden, activation='tanh', dropout=0.2, \n",
    "            return_state=True, return_sequences=True,name=('decoder' +str(i)))(enc_concat_attention)\n",
    "\n",
    "        decoder_input = RepeatVector(y_train.shape[1],name='dec_repeat_vector'+str(i))(encoder_last_h)\n",
    "        decoder_stack_h = LSTM(n_hidden, activation='tanh', dropout=0.2,\n",
    "         return_state=False, return_sequences=True,name=('dec_alignment_model'+str(i)))(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "        attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2], name=('dec_attention_dot'+str(i)))\n",
    "        attention = Activation('softmax', name='dec_attention_activation'+str(i))(attention)\n",
    "        context = dot([attention, encoder_stack_h], axes=[2,1],name='dec_Context'+str(i))\n",
    "        dec_head_list.append(context)\n",
    "    dec_concat_attention = Concatenate(axis=2)(dec_head_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = TimeDistributed(Dense(y_train.shape[2]))(dec_concat_attention)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = TimeDistributed(Dense(y_train.shape[2]))(dec_concat_attention)\n",
    "\n",
    "    model = Model(inputs=input_train, outputs=out)\n",
    "\n",
    "    model.compile(loss='MeanAbsoluteError', optimizer='Adam', metrics=['mse'])\n",
    "    return model, model_checkpoint_callback, checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32d2c889-2206-430d-98da-b909852a4423",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 231s 2s/step - loss: 0.2504 - mse: 0.2809 - val_loss: 0.1542 - val_mse: 0.0560\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 134s 1s/step - loss: 0.1991 - mse: 0.2358 - val_loss: 0.1544 - val_mse: 0.0519\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 134s 1s/step - loss: 0.1926 - mse: 0.2310 - val_loss: 0.1450 - val_mse: 0.0512\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 133s 1s/step - loss: 0.1879 - mse: 0.2279 - val_loss: 0.1699 - val_mse: 0.0588\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 133s 1s/step - loss: 0.1866 - mse: 0.2268 - val_loss: 0.1661 - val_mse: 0.0588\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1833 - mse: 0.2234 - val_loss: 0.1681 - val_mse: 0.0622\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 133s 1s/step - loss: 0.1799 - mse: 0.2201 - val_loss: 0.1428 - val_mse: 0.0531\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 133s 1s/step - loss: 0.1784 - mse: 0.2203 - val_loss: 0.2090 - val_mse: 0.0814\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1754 - mse: 0.2171 - val_loss: 0.1658 - val_mse: 0.0622\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 133s 1s/step - loss: 0.1771 - mse: 0.2165 - val_loss: 0.1807 - val_mse: 0.0688\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1709 - mse: 0.2145 - val_loss: 0.1814 - val_mse: 0.0701\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 133s 1s/step - loss: 0.1689 - mse: 0.2121 - val_loss: 0.2071 - val_mse: 0.0789\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 133s 1s/step - loss: 0.1690 - mse: 0.2100 - val_loss: 0.2015 - val_mse: 0.0823\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1659 - mse: 0.2088 - val_loss: 0.1677 - val_mse: 0.0640\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 133s 1s/step - loss: 0.1650 - mse: 0.2072 - val_loss: 0.1814 - val_mse: 0.0738\n",
      "101/101 [==============================] - 70s 511ms/step\n",
      "44/44 [==============================] - 22s 503ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/107 [==============================] - 237s 1s/step - loss: 0.4292 - mse: 0.6828 - val_loss: 0.3672 - val_mse: 0.4377\n",
      "Epoch 2/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3598 - mse: 0.5761 - val_loss: 0.3757 - val_mse: 0.4497\n",
      "Epoch 3/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3468 - mse: 0.5559 - val_loss: 0.3799 - val_mse: 0.4558\n",
      "Epoch 4/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3455 - mse: 0.5520 - val_loss: 0.3915 - val_mse: 0.4414\n",
      "Epoch 5/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3408 - mse: 0.5436 - val_loss: 0.4110 - val_mse: 0.4890\n",
      "Epoch 6/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3343 - mse: 0.5360 - val_loss: 0.5017 - val_mse: 0.5320\n",
      "Epoch 7/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3346 - mse: 0.5336 - val_loss: 0.5334 - val_mse: 0.5788\n",
      "Epoch 8/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3270 - mse: 0.5223 - val_loss: 0.5388 - val_mse: 0.5988\n",
      "Epoch 9/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3218 - mse: 0.5099 - val_loss: 0.5945 - val_mse: 0.6692\n",
      "Epoch 10/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3200 - mse: 0.5049 - val_loss: 0.7719 - val_mse: 0.9541\n",
      "Epoch 11/15\n",
      "107/107 [==============================] - 139s 1s/step - loss: 0.3159 - mse: 0.5016 - val_loss: 0.6679 - val_mse: 0.7882\n",
      "Epoch 12/15\n",
      "107/107 [==============================] - 139s 1s/step - loss: 0.3155 - mse: 0.4938 - val_loss: 0.6445 - val_mse: 0.7680\n",
      "Epoch 13/15\n",
      "107/107 [==============================] - 140s 1s/step - loss: 0.3120 - mse: 0.4893 - val_loss: 0.7329 - val_mse: 0.9344\n",
      "Epoch 14/15\n",
      "107/107 [==============================] - 139s 1s/step - loss: 0.3069 - mse: 0.4788 - val_loss: 0.7779 - val_mse: 0.9824\n",
      "Epoch 15/15\n",
      "107/107 [==============================] - 139s 1s/step - loss: 0.3049 - mse: 0.4717 - val_loss: 0.6492 - val_mse: 0.7568\n",
      "107/107 [==============================] - 69s 499ms/step\n",
      "46/46 [==============================] - 23s 497ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 226s 1s/step - loss: 0.2214 - mse: 0.1734 - val_loss: 0.2563 - val_mse: 0.3424\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.2016 - mse: 0.1573 - val_loss: 0.2337 - val_mse: 0.3474\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1961 - mse: 0.1530 - val_loss: 0.2463 - val_mse: 0.3405\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1931 - mse: 0.1503 - val_loss: 0.2654 - val_mse: 0.3343\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1895 - mse: 0.1473 - val_loss: 0.2365 - val_mse: 0.3370\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1856 - mse: 0.1442 - val_loss: 0.2627 - val_mse: 0.3336\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1821 - mse: 0.1408 - val_loss: 0.2844 - val_mse: 0.3454\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1790 - mse: 0.1386 - val_loss: 0.2671 - val_mse: 0.3502\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1763 - mse: 0.1357 - val_loss: 0.2916 - val_mse: 0.3545\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1737 - mse: 0.1327 - val_loss: 0.3035 - val_mse: 0.3624\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1732 - mse: 0.1312 - val_loss: 0.2729 - val_mse: 0.3635\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1700 - mse: 0.1293 - val_loss: 0.2906 - val_mse: 0.3606\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1672 - mse: 0.1267 - val_loss: 0.2706 - val_mse: 0.3659\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1662 - mse: 0.1258 - val_loss: 0.3074 - val_mse: 0.3805\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1624 - mse: 0.1217 - val_loss: 0.3023 - val_mse: 0.3864\n",
      "101/101 [==============================] - 66s 500ms/step\n",
      "44/44 [==============================] - 22s 492ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82/82 [==============================] - 205s 2s/step - loss: 0.2235 - mse: 0.2358 - val_loss: 0.1396 - val_mse: 0.0521\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1394 - mse: 0.1632 - val_loss: 0.1453 - val_mse: 0.0442\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1287 - mse: 0.1586 - val_loss: 0.1352 - val_mse: 0.0411\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 108s 1s/step - loss: 0.1259 - mse: 0.1556 - val_loss: 0.1313 - val_mse: 0.0455\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1242 - mse: 0.1544 - val_loss: 0.1409 - val_mse: 0.0431\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1223 - mse: 0.1537 - val_loss: 0.1349 - val_mse: 0.0443\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 106s 1s/step - loss: 0.1216 - mse: 0.1525 - val_loss: 0.1337 - val_mse: 0.0432\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1178 - mse: 0.1530 - val_loss: 0.1453 - val_mse: 0.0423\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 108s 1s/step - loss: 0.1196 - mse: 0.1524 - val_loss: 0.1304 - val_mse: 0.0402\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 108s 1s/step - loss: 0.1158 - mse: 0.1498 - val_loss: 0.1226 - val_mse: 0.0383\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1137 - mse: 0.1496 - val_loss: 0.1320 - val_mse: 0.0434\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1134 - mse: 0.1494 - val_loss: 0.1357 - val_mse: 0.0485\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 108s 1s/step - loss: 0.1104 - mse: 0.1468 - val_loss: 0.1329 - val_mse: 0.0460\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1127 - mse: 0.1474 - val_loss: 0.1321 - val_mse: 0.0398\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 107s 1s/step - loss: 0.1081 - mse: 0.1449 - val_loss: 0.1338 - val_mse: 0.0460\n",
      "82/82 [==============================] - 57s 501ms/step\n",
      "36/36 [==============================] - 18s 493ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 234s 2s/step - loss: 0.1839 - mse: 0.1262 - val_loss: 0.1420 - val_mse: 0.0435\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1381 - mse: 0.0915 - val_loss: 0.1558 - val_mse: 0.0450\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1355 - mse: 0.0869 - val_loss: 0.1336 - val_mse: 0.0391\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1313 - mse: 0.0808 - val_loss: 0.1660 - val_mse: 0.0470\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1287 - mse: 0.0763 - val_loss: 0.1900 - val_mse: 0.0544\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1300 - mse: 0.0701 - val_loss: 0.1381 - val_mse: 0.0402\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1218 - mse: 0.0619 - val_loss: 0.1479 - val_mse: 0.0424\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1213 - mse: 0.0579 - val_loss: 0.1715 - val_mse: 0.0494\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1175 - mse: 0.0537 - val_loss: 0.1541 - val_mse: 0.0445\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1176 - mse: 0.0527 - val_loss: 0.1749 - val_mse: 0.0500\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1150 - mse: 0.0542 - val_loss: 0.1483 - val_mse: 0.0455\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1145 - mse: 0.0497 - val_loss: 0.1602 - val_mse: 0.0492\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1137 - mse: 0.0516 - val_loss: 0.1507 - val_mse: 0.0469\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1117 - mse: 0.0480 - val_loss: 0.1721 - val_mse: 0.0514\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.1086 - mse: 0.0458 - val_loss: 0.1693 - val_mse: 0.0528\n",
      "101/101 [==============================] - 68s 499ms/step\n",
      "44/44 [==============================] - 22s 502ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=288\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0, 1, 2, 3, 4]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    X_train= denoise_array(X_train, 0, 'db4', 2, 3)\n",
    "    X_val= denoise_array(X_val, 0, 'db4', 2, 3)\n",
    "    X_train = add_mp_reversed(X_train, mp_window)\n",
    "    X_val = add_mp_reversed(X_val, mp_window)\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_wavelet_mae/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_wavelet_mae/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_wavelet_mae/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_wavelet_mae/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_wavelet_mae/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3199aea-e95c-4ab7-9bc1-9777996950d5",
   "metadata": {},
   "source": [
    "## Bior wavelet, less aggresive denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c871c698-bc48-41fc-b751-4e4bd613f371",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 229s 1s/step - loss: 0.2707 - mae: 0.2650 - val_loss: 0.0475 - val_mae: 0.1416\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.2260 - mae: 0.2136 - val_loss: 0.0512 - val_mae: 0.1589\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.2224 - mae: 0.2128 - val_loss: 0.0729 - val_mae: 0.2013\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.2177 - mae: 0.2095 - val_loss: 0.0583 - val_mae: 0.1692\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.2132 - mae: 0.2083 - val_loss: 0.0515 - val_mae: 0.1499\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.2080 - mae: 0.2031 - val_loss: 0.0513 - val_mae: 0.1488\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.2021 - mae: 0.1989 - val_loss: 0.0543 - val_mae: 0.1518\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1975 - mae: 0.1978 - val_loss: 0.0542 - val_mae: 0.1499\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1961 - mae: 0.1971 - val_loss: 0.0766 - val_mae: 0.1908\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1874 - mae: 0.1921 - val_loss: 0.0556 - val_mae: 0.1528\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1878 - mae: 0.1924 - val_loss: 0.0559 - val_mae: 0.1480\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 123s 1s/step - loss: 0.1878 - mae: 0.1946 - val_loss: 0.0640 - val_mae: 0.1646\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1794 - mae: 0.1885 - val_loss: 0.0632 - val_mae: 0.1611\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1792 - mae: 0.1890 - val_loss: 0.0822 - val_mae: 0.1860\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 123s 1s/step - loss: 0.1776 - mae: 0.1859 - val_loss: 0.0649 - val_mae: 0.1602\n",
      "101/101 [==============================] - 66s 459ms/step\n",
      "44/44 [==============================] - 20s 458ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/107 [==============================] - 229s 1s/step - loss: 0.7073 - mae: 0.4874 - val_loss: 0.4192 - val_mae: 0.3936\n",
      "Epoch 2/15\n",
      "107/107 [==============================] - 130s 1s/step - loss: 0.5465 - mae: 0.3811 - val_loss: 0.4295 - val_mae: 0.4130\n",
      "Epoch 3/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.5307 - mae: 0.3755 - val_loss: 0.4166 - val_mae: 0.3611\n",
      "Epoch 4/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.5215 - mae: 0.3713 - val_loss: 0.4223 - val_mae: 0.3957\n",
      "Epoch 5/15\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.5150 - mae: 0.3719 - val_loss: 0.4582 - val_mae: 0.4045\n",
      "Epoch 6/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4899 - mae: 0.3603 - val_loss: 0.4756 - val_mae: 0.4675\n",
      "Epoch 7/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4808 - mae: 0.3621 - val_loss: 0.4808 - val_mae: 0.4604\n",
      "Epoch 8/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4616 - mae: 0.3559 - val_loss: 0.6672 - val_mae: 0.6266\n",
      "Epoch 9/15\n",
      "107/107 [==============================] - 127s 1s/step - loss: 0.4603 - mae: 0.3541 - val_loss: 0.6200 - val_mae: 0.5751\n",
      "Epoch 10/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4424 - mae: 0.3496 - val_loss: 0.5520 - val_mae: 0.4680\n",
      "Epoch 11/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4253 - mae: 0.3418 - val_loss: 0.7169 - val_mae: 0.6291\n",
      "Epoch 12/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4232 - mae: 0.3386 - val_loss: 0.6101 - val_mae: 0.5603\n",
      "Epoch 13/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4112 - mae: 0.3396 - val_loss: 0.8298 - val_mae: 0.7132\n",
      "Epoch 14/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3908 - mae: 0.3277 - val_loss: 0.9006 - val_mae: 0.7343\n",
      "Epoch 15/15\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3844 - mae: 0.3236 - val_loss: 0.6877 - val_mae: 0.5553\n",
      "107/107 [==============================] - 65s 457ms/step\n",
      "46/46 [==============================] - 21s 458ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 217s 1s/step - loss: 0.1675 - mae: 0.2316 - val_loss: 0.3544 - val_mae: 0.3100\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1493 - mae: 0.2083 - val_loss: 0.3471 - val_mae: 0.2360\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 123s 1s/step - loss: 0.1451 - mae: 0.2065 - val_loss: 0.3400 - val_mae: 0.2782\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1382 - mae: 0.2011 - val_loss: 0.3463 - val_mae: 0.2590\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1354 - mae: 0.1995 - val_loss: 0.3517 - val_mae: 0.2799\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1294 - mae: 0.1951 - val_loss: 0.3533 - val_mae: 0.2612\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1282 - mae: 0.1936 - val_loss: 0.3790 - val_mae: 0.3008\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1243 - mae: 0.1889 - val_loss: 0.3728 - val_mae: 0.3296\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1201 - mae: 0.1865 - val_loss: 0.3718 - val_mae: 0.2950\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1195 - mae: 0.1865 - val_loss: 0.3709 - val_mae: 0.3020\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1174 - mae: 0.1838 - val_loss: 0.4049 - val_mae: 0.3326\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1153 - mae: 0.1823 - val_loss: 0.4013 - val_mae: 0.3338\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1111 - mae: 0.1771 - val_loss: 0.4098 - val_mae: 0.3434\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.1103 - mae: 0.1768 - val_loss: 0.4174 - val_mae: 0.3637\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1089 - mae: 0.1749 - val_loss: 0.4123 - val_mae: 0.3567\n",
      "101/101 [==============================] - 62s 453ms/step\n",
      "44/44 [==============================] - 20s 453ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82/82 [==============================] - 197s 1s/step - loss: 0.2235 - mae: 0.2246 - val_loss: 0.0915 - val_mae: 0.2210\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 100s 1s/step - loss: 0.1611 - mae: 0.1512 - val_loss: 0.0476 - val_mae: 0.1347\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 99s 1s/step - loss: 0.1548 - mae: 0.1431 - val_loss: 0.0524 - val_mae: 0.1412\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 99s 1s/step - loss: 0.1545 - mae: 0.1465 - val_loss: 0.0392 - val_mae: 0.1246\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 98s 1s/step - loss: 0.1505 - mae: 0.1427 - val_loss: 0.0464 - val_mae: 0.1531\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 98s 1s/step - loss: 0.1447 - mae: 0.1350 - val_loss: 0.0416 - val_mae: 0.1241\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 99s 1s/step - loss: 0.1450 - mae: 0.1389 - val_loss: 0.0436 - val_mae: 0.1374\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 97s 1s/step - loss: 0.1428 - mae: 0.1366 - val_loss: 0.0446 - val_mae: 0.1319\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 99s 1s/step - loss: 0.1364 - mae: 0.1334 - val_loss: 0.0507 - val_mae: 0.1433\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 98s 1s/step - loss: 0.1305 - mae: 0.1301 - val_loss: 0.0427 - val_mae: 0.1296\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 98s 1s/step - loss: 0.1358 - mae: 0.1364 - val_loss: 0.0462 - val_mae: 0.1357\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 98s 1s/step - loss: 0.1341 - mae: 0.1369 - val_loss: 0.0518 - val_mae: 0.1481\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 98s 1s/step - loss: 0.1294 - mae: 0.1295 - val_loss: 0.0430 - val_mae: 0.1484\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 97s 1s/step - loss: 0.1282 - mae: 0.1271 - val_loss: 0.0538 - val_mae: 0.1453\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 98s 1s/step - loss: 0.1241 - mae: 0.1228 - val_loss: 0.0511 - val_mae: 0.1481\n",
      "82/82 [==============================] - 53s 453ms/step\n",
      "36/36 [==============================] - 16s 449ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 226s 1s/step - loss: 0.1188 - mae: 0.1891 - val_loss: 0.0781 - val_mae: 0.2120\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.0768 - mae: 0.1520 - val_loss: 0.0706 - val_mae: 0.2241\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.0645 - mae: 0.1410 - val_loss: 0.0783 - val_mae: 0.2413\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.0645 - mae: 0.1377 - val_loss: 0.0840 - val_mae: 0.2506\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.0575 - mae: 0.1340 - val_loss: 0.0601 - val_mae: 0.1976\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.0535 - mae: 0.1326 - val_loss: 0.0537 - val_mae: 0.1845\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.0552 - mae: 0.1354 - val_loss: 0.0696 - val_mae: 0.2153\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.0476 - mae: 0.1241 - val_loss: 0.0566 - val_mae: 0.1810\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0463 - mae: 0.1241 - val_loss: 0.0550 - val_mae: 0.1837\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0453 - mae: 0.1198 - val_loss: 0.0593 - val_mae: 0.1926\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.0527 - mae: 0.1264 - val_loss: 0.0662 - val_mae: 0.1902\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.0435 - mae: 0.1203 - val_loss: 0.0612 - val_mae: 0.1929\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.0448 - mae: 0.1207 - val_loss: 0.0713 - val_mae: 0.2075\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.0453 - mae: 0.1228 - val_loss: 0.0483 - val_mae: 0.1626\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0420 - mae: 0.1165 - val_loss: 0.0623 - val_mae: 0.1917\n",
      "101/101 [==============================] - 63s 454ms/step\n",
      "44/44 [==============================] - 20s 458ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=288\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0, 1, 2, 3, 4]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    X_train= denoise_array(X_train, 0, 'bior3.3', 2, 10)\n",
    "    X_val= denoise_array(X_val, 0, 'bior3.3', 2, 10)\n",
    "    X_train = add_mp_reversed(X_train, mp_window)\n",
    "    X_val = add_mp_reversed(X_val, mp_window)\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_wavelet2/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_wavelet2/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_wavelet2/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_wavelet2/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_wavelet2/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28232ccb-fa98-425e-9b7b-90711355c388",
   "metadata": {},
   "source": [
    "## 12 hour MP window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b07e989a-ee27-4cbc-a202-4ea2933a6659",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "104/104 [==============================] - 232s 1s/step - loss: 0.4024 - mae: 0.2867 - val_loss: 0.0521 - val_mae: 0.1549\n",
      "Epoch 2/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.3476 - mae: 0.2301 - val_loss: 0.0535 - val_mae: 0.1540\n",
      "Epoch 3/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.3448 - mae: 0.2294 - val_loss: 0.0549 - val_mae: 0.1554\n",
      "Epoch 4/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.3381 - mae: 0.2280 - val_loss: 0.0610 - val_mae: 0.1596\n",
      "Epoch 5/15\n",
      "104/104 [==============================] - 124s 1s/step - loss: 0.3265 - mae: 0.2269 - val_loss: 0.0567 - val_mae: 0.1486\n",
      "Epoch 6/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.3282 - mae: 0.2259 - val_loss: 0.0541 - val_mae: 0.1498\n",
      "Epoch 7/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.3148 - mae: 0.2218 - val_loss: 0.0542 - val_mae: 0.1543\n",
      "Epoch 8/15\n",
      "104/104 [==============================] - 124s 1s/step - loss: 0.3056 - mae: 0.2204 - val_loss: 0.0564 - val_mae: 0.1573\n",
      "Epoch 9/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.3116 - mae: 0.2199 - val_loss: 0.0717 - val_mae: 0.2043\n",
      "Epoch 10/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2953 - mae: 0.2203 - val_loss: 0.0664 - val_mae: 0.1669\n",
      "Epoch 11/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2915 - mae: 0.2149 - val_loss: 0.0778 - val_mae: 0.1954\n",
      "Epoch 12/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2887 - mae: 0.2199 - val_loss: 0.0804 - val_mae: 0.1834\n",
      "Epoch 13/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2860 - mae: 0.2114 - val_loss: 0.0558 - val_mae: 0.1578\n",
      "Epoch 14/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2806 - mae: 0.2114 - val_loss: 0.0640 - val_mae: 0.1634\n",
      "Epoch 15/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2609 - mae: 0.2020 - val_loss: 0.0702 - val_mae: 0.1733\n",
      "104/104 [==============================] - 65s 456ms/step\n",
      "45/45 [==============================] - 20s 455ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "111/111 [==============================] - 238s 1s/step - loss: 0.7107 - mae: 0.4845 - val_loss: 0.4200 - val_mae: 0.4063\n",
      "Epoch 2/15\n",
      "111/111 [==============================] - 134s 1s/step - loss: 0.5750 - mae: 0.3986 - val_loss: 0.4291 - val_mae: 0.3616\n",
      "Epoch 3/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.5570 - mae: 0.3898 - val_loss: 0.3941 - val_mae: 0.3603\n",
      "Epoch 4/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.5428 - mae: 0.3818 - val_loss: 0.4265 - val_mae: 0.3626\n",
      "Epoch 5/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.5260 - mae: 0.3784 - val_loss: 0.5372 - val_mae: 0.4716\n",
      "Epoch 6/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.5133 - mae: 0.3716 - val_loss: 0.3955 - val_mae: 0.3838\n",
      "Epoch 7/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.5079 - mae: 0.3745 - val_loss: 0.4006 - val_mae: 0.3673\n",
      "Epoch 8/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.4926 - mae: 0.3717 - val_loss: 0.5473 - val_mae: 0.4287\n",
      "Epoch 9/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.4918 - mae: 0.3731 - val_loss: 0.4875 - val_mae: 0.4002\n",
      "Epoch 10/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.4613 - mae: 0.3576 - val_loss: 0.4513 - val_mae: 0.3922\n",
      "Epoch 11/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.4491 - mae: 0.3507 - val_loss: 0.5330 - val_mae: 0.4188\n",
      "Epoch 12/15\n",
      "111/111 [==============================] - 134s 1s/step - loss: 0.4441 - mae: 0.3535 - val_loss: 0.5089 - val_mae: 0.4002\n",
      "Epoch 13/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.4736 - mae: 0.3620 - val_loss: 0.6570 - val_mae: 0.5034\n",
      "Epoch 14/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.4384 - mae: 0.3498 - val_loss: 0.5221 - val_mae: 0.4122\n",
      "Epoch 15/15\n",
      "111/111 [==============================] - 133s 1s/step - loss: 0.4194 - mae: 0.3418 - val_loss: 0.6813 - val_mae: 0.5241\n",
      "111/111 [==============================] - 68s 457ms/step\n",
      "48/48 [==============================] - 22s 452ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "104/104 [==============================] - 232s 1s/step - loss: 0.2677 - mae: 0.2510 - val_loss: 0.3427 - val_mae: 0.2421\n",
      "Epoch 2/15\n",
      "104/104 [==============================] - 126s 1s/step - loss: 0.2444 - mae: 0.2254 - val_loss: 0.3308 - val_mae: 0.2372\n",
      "Epoch 3/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2388 - mae: 0.2262 - val_loss: 0.3346 - val_mae: 0.3004\n",
      "Epoch 4/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2314 - mae: 0.2217 - val_loss: 0.3249 - val_mae: 0.2521\n",
      "Epoch 5/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2261 - mae: 0.2216 - val_loss: 0.3277 - val_mae: 0.2477\n",
      "Epoch 6/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2159 - mae: 0.2138 - val_loss: 0.3326 - val_mae: 0.2976\n",
      "Epoch 7/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2116 - mae: 0.2094 - val_loss: 0.3573 - val_mae: 0.3382\n",
      "Epoch 8/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2061 - mae: 0.2064 - val_loss: 0.3624 - val_mae: 0.3429\n",
      "Epoch 9/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2041 - mae: 0.2055 - val_loss: 0.3608 - val_mae: 0.3252\n",
      "Epoch 10/15\n",
      "104/104 [==============================] - 127s 1s/step - loss: 0.1968 - mae: 0.1996 - val_loss: 0.3492 - val_mae: 0.2908\n",
      "Epoch 11/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.1957 - mae: 0.1986 - val_loss: 0.3711 - val_mae: 0.3455\n",
      "Epoch 12/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2038 - mae: 0.2009 - val_loss: 0.3589 - val_mae: 0.3235\n",
      "Epoch 13/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.2013 - mae: 0.2029 - val_loss: 0.3471 - val_mae: 0.2912\n",
      "Epoch 14/15\n",
      "104/104 [==============================] - 126s 1s/step - loss: 0.1889 - mae: 0.1923 - val_loss: 0.3758 - val_mae: 0.3482\n",
      "Epoch 15/15\n",
      "104/104 [==============================] - 126s 1s/step - loss: 0.1859 - mae: 0.1878 - val_loss: 0.3679 - val_mae: 0.3139\n",
      "104/104 [==============================] - 65s 454ms/step\n",
      "45/45 [==============================] - 20s 453ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "85/85 [==============================] - 198s 1s/step - loss: 0.2409 - mae: 0.2114 - val_loss: 0.0470 - val_mae: 0.1315\n",
      "Epoch 2/15\n",
      "85/85 [==============================] - 103s 1s/step - loss: 0.1802 - mae: 0.1504 - val_loss: 0.0387 - val_mae: 0.1213\n",
      "Epoch 3/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1765 - mae: 0.1513 - val_loss: 0.0408 - val_mae: 0.1416\n",
      "Epoch 4/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1773 - mae: 0.1541 - val_loss: 0.0408 - val_mae: 0.1268\n",
      "Epoch 5/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1691 - mae: 0.1419 - val_loss: 0.0516 - val_mae: 0.1855\n",
      "Epoch 6/15\n",
      "85/85 [==============================] - 103s 1s/step - loss: 0.1702 - mae: 0.1531 - val_loss: 0.0376 - val_mae: 0.1265\n",
      "Epoch 7/15\n",
      "85/85 [==============================] - 103s 1s/step - loss: 0.1625 - mae: 0.1415 - val_loss: 0.0426 - val_mae: 0.1328\n",
      "Epoch 8/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1552 - mae: 0.1383 - val_loss: 0.0382 - val_mae: 0.1390\n",
      "Epoch 9/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1494 - mae: 0.1358 - val_loss: 0.0380 - val_mae: 0.1246\n",
      "Epoch 10/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1495 - mae: 0.1332 - val_loss: 0.0402 - val_mae: 0.1427\n",
      "Epoch 11/15\n",
      "85/85 [==============================] - 101s 1s/step - loss: 0.1458 - mae: 0.1325 - val_loss: 0.0391 - val_mae: 0.1242\n",
      "Epoch 12/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1443 - mae: 0.1312 - val_loss: 0.0396 - val_mae: 0.1303\n",
      "Epoch 13/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1436 - mae: 0.1303 - val_loss: 0.0384 - val_mae: 0.1246\n",
      "Epoch 14/15\n",
      "85/85 [==============================] - 103s 1s/step - loss: 0.1403 - mae: 0.1255 - val_loss: 0.0413 - val_mae: 0.1270\n",
      "Epoch 15/15\n",
      "85/85 [==============================] - 102s 1s/step - loss: 0.1413 - mae: 0.1285 - val_loss: 0.0400 - val_mae: 0.1227\n",
      "85/85 [==============================] - 65s 458ms/step\n",
      "37/37 [==============================] - 17s 451ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "104/104 [==============================] - 223s 1s/step - loss: 0.1248 - mae: 0.2048 - val_loss: 0.0652 - val_mae: 0.2089\n",
      "Epoch 2/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0759 - mae: 0.1468 - val_loss: 0.0637 - val_mae: 0.1911\n",
      "Epoch 3/15\n",
      "104/104 [==============================] - 126s 1s/step - loss: 0.0588 - mae: 0.1350 - val_loss: 0.0644 - val_mae: 0.2013\n",
      "Epoch 4/15\n",
      "104/104 [==============================] - 123s 1s/step - loss: 0.0608 - mae: 0.1388 - val_loss: 0.0671 - val_mae: 0.2132\n",
      "Epoch 5/15\n",
      "104/104 [==============================] - 126s 1s/step - loss: 0.0588 - mae: 0.1344 - val_loss: 0.0486 - val_mae: 0.1678\n",
      "Epoch 6/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0554 - mae: 0.1335 - val_loss: 0.0648 - val_mae: 0.2040\n",
      "Epoch 7/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0521 - mae: 0.1309 - val_loss: 0.0628 - val_mae: 0.2015\n",
      "Epoch 8/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0499 - mae: 0.1279 - val_loss: 0.0813 - val_mae: 0.2446\n",
      "Epoch 9/15\n",
      "104/104 [==============================] - 124s 1s/step - loss: 0.0481 - mae: 0.1264 - val_loss: 0.0610 - val_mae: 0.1960\n",
      "Epoch 10/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0457 - mae: 0.1244 - val_loss: 0.0792 - val_mae: 0.2237\n",
      "Epoch 11/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0496 - mae: 0.1241 - val_loss: 0.0771 - val_mae: 0.2011\n",
      "Epoch 12/15\n",
      "104/104 [==============================] - 124s 1s/step - loss: 0.0445 - mae: 0.1215 - val_loss: 0.0510 - val_mae: 0.1715\n",
      "Epoch 13/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0460 - mae: 0.1230 - val_loss: 0.0571 - val_mae: 0.1776\n",
      "Epoch 14/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0422 - mae: 0.1191 - val_loss: 0.0612 - val_mae: 0.1787\n",
      "Epoch 15/15\n",
      "104/104 [==============================] - 125s 1s/step - loss: 0.0408 - mae: 0.1162 - val_loss: 0.0914 - val_mae: 0.2195\n",
      "104/104 [==============================] - 73s 458ms/step\n",
      "45/45 [==============================] - 21s 455ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+144\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=144\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0, 1, 2, 3, 4]:\n",
    "    n_steps_in = 4032+144\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    X_train= denoise_array(X_train, 0, 'bior3.3', 2, 10)\n",
    "    X_val= denoise_array(X_val, 0, 'bior3.3', 2, 10)\n",
    "    X_train = add_mp_reversed(X_train, mp_window)\n",
    "    X_val = add_mp_reversed(X_val, mp_window)\n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_wavelet3/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_wavelet3/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_wavelet3/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_wavelet3/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_wavelet3/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9410331-3000-4644-8a56-7c6036cb3280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "101/101 [==============================] - 223s 1s/step - loss: 0.2786 - mae: 0.2731 - val_loss: 0.0565 - val_mae: 0.1690\n",
      "Epoch 2/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.2299 - mae: 0.2209 - val_loss: 0.0561 - val_mae: 0.1596\n",
      "Epoch 3/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.2192 - mae: 0.2077 - val_loss: 0.0551 - val_mae: 0.1530\n",
      "Epoch 4/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.2133 - mae: 0.2100 - val_loss: 0.0708 - val_mae: 0.1875\n",
      "Epoch 5/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.2063 - mae: 0.2049 - val_loss: 0.0516 - val_mae: 0.1422\n",
      "Epoch 6/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.2037 - mae: 0.1999 - val_loss: 0.0541 - val_mae: 0.1508\n",
      "Epoch 7/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.2048 - mae: 0.2009 - val_loss: 0.0567 - val_mae: 0.1577\n",
      "Epoch 8/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1960 - mae: 0.1958 - val_loss: 0.0918 - val_mae: 0.1869\n",
      "Epoch 9/35\n",
      "101/101 [==============================] - 123s 1s/step - loss: 0.1966 - mae: 0.1962 - val_loss: 0.0559 - val_mae: 0.1475\n",
      "Epoch 10/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1933 - mae: 0.1956 - val_loss: 0.0693 - val_mae: 0.1768\n",
      "Epoch 11/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1871 - mae: 0.1904 - val_loss: 0.0617 - val_mae: 0.1576\n",
      "Epoch 12/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1837 - mae: 0.1893 - val_loss: 0.0849 - val_mae: 0.1987\n",
      "Epoch 13/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1807 - mae: 0.1862 - val_loss: 0.0802 - val_mae: 0.1937\n",
      "Epoch 14/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1795 - mae: 0.1861 - val_loss: 0.0806 - val_mae: 0.1950\n",
      "Epoch 15/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1747 - mae: 0.1825 - val_loss: 0.0864 - val_mae: 0.2069\n",
      "Epoch 16/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1759 - mae: 0.1870 - val_loss: 0.0681 - val_mae: 0.1715\n",
      "Epoch 17/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1698 - mae: 0.1827 - val_loss: 0.0880 - val_mae: 0.1872\n",
      "Epoch 18/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1682 - mae: 0.1781 - val_loss: 0.0745 - val_mae: 0.1758\n",
      "Epoch 19/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1647 - mae: 0.1776 - val_loss: 0.0852 - val_mae: 0.1930\n",
      "Epoch 20/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1632 - mae: 0.1753 - val_loss: 0.0914 - val_mae: 0.2052\n",
      "Epoch 21/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1607 - mae: 0.1752 - val_loss: 0.0868 - val_mae: 0.1915\n",
      "Epoch 22/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1598 - mae: 0.1752 - val_loss: 0.0755 - val_mae: 0.1726\n",
      "Epoch 23/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1531 - mae: 0.1703 - val_loss: 0.0872 - val_mae: 0.1882\n",
      "Epoch 24/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1539 - mae: 0.1711 - val_loss: 0.0990 - val_mae: 0.2074\n",
      "Epoch 25/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1568 - mae: 0.1675 - val_loss: 0.0876 - val_mae: 0.1903\n",
      "Epoch 26/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1484 - mae: 0.1663 - val_loss: 0.0799 - val_mae: 0.1859\n",
      "Epoch 27/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1455 - mae: 0.1644 - val_loss: 0.0704 - val_mae: 0.1709\n",
      "Epoch 28/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1450 - mae: 0.1688 - val_loss: 0.0934 - val_mae: 0.2062\n",
      "Epoch 29/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1415 - mae: 0.1647 - val_loss: 0.0884 - val_mae: 0.1964\n",
      "Epoch 30/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1507 - mae: 0.1673 - val_loss: 0.0785 - val_mae: 0.1873\n",
      "Epoch 31/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1560 - mae: 0.1689 - val_loss: 0.0733 - val_mae: 0.1733\n",
      "Epoch 32/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1477 - mae: 0.1649 - val_loss: 0.0729 - val_mae: 0.1729\n",
      "Epoch 33/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1488 - mae: 0.1688 - val_loss: 0.0818 - val_mae: 0.1776\n",
      "Epoch 34/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1415 - mae: 0.1673 - val_loss: 0.0812 - val_mae: 0.1890\n",
      "Epoch 35/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1474 - mae: 0.1642 - val_loss: 0.0727 - val_mae: 0.1813\n",
      "101/101 [==============================] - 64s 454ms/step\n",
      "44/44 [==============================] - 20s 455ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "107/107 [==============================] - 224s 1s/step - loss: 0.7468 - mae: 0.5055 - val_loss: 0.4229 - val_mae: 0.3766\n",
      "Epoch 2/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.5521 - mae: 0.3851 - val_loss: 0.3801 - val_mae: 0.3618\n",
      "Epoch 3/35\n",
      "107/107 [==============================] - 127s 1s/step - loss: 0.5350 - mae: 0.3797 - val_loss: 0.4156 - val_mae: 0.3734\n",
      "Epoch 4/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.5240 - mae: 0.3751 - val_loss: 0.4208 - val_mae: 0.3718\n",
      "Epoch 5/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.5229 - mae: 0.3744 - val_loss: 0.4100 - val_mae: 0.4135\n",
      "Epoch 6/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.5025 - mae: 0.3696 - val_loss: 0.4372 - val_mae: 0.4398\n",
      "Epoch 7/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.4851 - mae: 0.3627 - val_loss: 0.4265 - val_mae: 0.4030\n",
      "Epoch 8/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.4714 - mae: 0.3601 - val_loss: 0.4378 - val_mae: 0.4368\n",
      "Epoch 9/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.4523 - mae: 0.3533 - val_loss: 0.4372 - val_mae: 0.4193\n",
      "Epoch 10/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4443 - mae: 0.3536 - val_loss: 0.5126 - val_mae: 0.5165\n",
      "Epoch 11/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.4219 - mae: 0.3416 - val_loss: 0.4559 - val_mae: 0.4355\n",
      "Epoch 12/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.4105 - mae: 0.3365 - val_loss: 0.5904 - val_mae: 0.5504\n",
      "Epoch 13/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3975 - mae: 0.3338 - val_loss: 0.7724 - val_mae: 0.7128\n",
      "Epoch 14/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.4024 - mae: 0.3331 - val_loss: 0.5064 - val_mae: 0.4129\n",
      "Epoch 15/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3915 - mae: 0.3286 - val_loss: 0.7085 - val_mae: 0.6539\n",
      "Epoch 16/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3850 - mae: 0.3270 - val_loss: 0.4819 - val_mae: 0.3976\n",
      "Epoch 17/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3875 - mae: 0.3286 - val_loss: 0.5460 - val_mae: 0.5073\n",
      "Epoch 18/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3791 - mae: 0.3236 - val_loss: 0.5291 - val_mae: 0.4739\n",
      "Epoch 19/35\n",
      "107/107 [==============================] - 130s 1s/step - loss: 0.3643 - mae: 0.3159 - val_loss: 0.4631 - val_mae: 0.4115\n",
      "Epoch 20/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3642 - mae: 0.3162 - val_loss: 0.6205 - val_mae: 0.5717\n",
      "Epoch 21/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3589 - mae: 0.3132 - val_loss: 0.6361 - val_mae: 0.5794\n",
      "Epoch 22/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3509 - mae: 0.3125 - val_loss: 0.5962 - val_mae: 0.5428\n",
      "Epoch 23/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3461 - mae: 0.3087 - val_loss: 0.5280 - val_mae: 0.4847\n",
      "Epoch 24/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3388 - mae: 0.3041 - val_loss: 0.6378 - val_mae: 0.5685\n",
      "Epoch 25/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3590 - mae: 0.3146 - val_loss: 0.6251 - val_mae: 0.5440\n",
      "Epoch 26/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3526 - mae: 0.3132 - val_loss: 0.5344 - val_mae: 0.4738\n",
      "Epoch 27/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3424 - mae: 0.3061 - val_loss: 0.6548 - val_mae: 0.5331\n",
      "Epoch 28/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3310 - mae: 0.3003 - val_loss: 0.6164 - val_mae: 0.5448\n",
      "Epoch 29/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3199 - mae: 0.2979 - val_loss: 0.5408 - val_mae: 0.5025\n",
      "Epoch 30/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3240 - mae: 0.2987 - val_loss: 0.5623 - val_mae: 0.4984\n",
      "Epoch 31/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3110 - mae: 0.2953 - val_loss: 0.5354 - val_mae: 0.4593\n",
      "Epoch 32/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3243 - mae: 0.3029 - val_loss: 0.5586 - val_mae: 0.5136\n",
      "Epoch 33/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.3317 - mae: 0.3056 - val_loss: 0.5871 - val_mae: 0.5381\n",
      "Epoch 34/35\n",
      "107/107 [==============================] - 128s 1s/step - loss: 0.3190 - mae: 0.2992 - val_loss: 0.6233 - val_mae: 0.5629\n",
      "Epoch 35/35\n",
      "107/107 [==============================] - 129s 1s/step - loss: 0.2962 - mae: 0.2890 - val_loss: 0.5588 - val_mae: 0.4945\n",
      "107/107 [==============================] - 75s 457ms/step\n",
      "46/46 [==============================] - 21s 458ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "101/101 [==============================] - 222s 1s/step - loss: 0.1634 - mae: 0.2254 - val_loss: 0.3507 - val_mae: 0.2367\n",
      "Epoch 2/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1542 - mae: 0.2149 - val_loss: 0.3381 - val_mae: 0.2697\n",
      "Epoch 3/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1480 - mae: 0.2088 - val_loss: 0.3463 - val_mae: 0.2329\n",
      "Epoch 4/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1426 - mae: 0.2033 - val_loss: 0.3514 - val_mae: 0.2478\n",
      "Epoch 5/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1379 - mae: 0.2025 - val_loss: 0.3498 - val_mae: 0.2723\n",
      "Epoch 6/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1297 - mae: 0.1949 - val_loss: 0.3542 - val_mae: 0.2725\n",
      "Epoch 7/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1262 - mae: 0.1907 - val_loss: 0.3545 - val_mae: 0.2563\n",
      "Epoch 8/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1240 - mae: 0.1908 - val_loss: 0.3624 - val_mae: 0.2520\n",
      "Epoch 9/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1207 - mae: 0.1880 - val_loss: 0.3871 - val_mae: 0.3101\n",
      "Epoch 10/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1185 - mae: 0.1849 - val_loss: 0.3817 - val_mae: 0.3364\n",
      "Epoch 11/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1191 - mae: 0.1863 - val_loss: 0.3781 - val_mae: 0.3038\n",
      "Epoch 12/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1146 - mae: 0.1829 - val_loss: 0.3857 - val_mae: 0.3354\n",
      "Epoch 13/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1111 - mae: 0.1784 - val_loss: 0.3824 - val_mae: 0.3267\n",
      "Epoch 14/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1079 - mae: 0.1754 - val_loss: 0.3699 - val_mae: 0.2907\n",
      "Epoch 15/35\n",
      "101/101 [==============================] - 122s 1s/step - loss: 0.1073 - mae: 0.1736 - val_loss: 0.3883 - val_mae: 0.3235\n",
      "Epoch 16/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.1042 - mae: 0.1712 - val_loss: 0.3943 - val_mae: 0.3208\n",
      "Epoch 17/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1032 - mae: 0.1686 - val_loss: 0.3949 - val_mae: 0.3286\n",
      "Epoch 18/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.1001 - mae: 0.1661 - val_loss: 0.3918 - val_mae: 0.3343\n",
      "Epoch 19/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.1041 - mae: 0.1680 - val_loss: 0.3820 - val_mae: 0.2964\n",
      "Epoch 20/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.1010 - mae: 0.1665 - val_loss: 0.3992 - val_mae: 0.3183\n",
      "Epoch 21/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.1004 - mae: 0.1668 - val_loss: 0.4265 - val_mae: 0.3914\n",
      "Epoch 22/35\n",
      "101/101 [==============================] - 119s 1s/step - loss: 0.0967 - mae: 0.1629 - val_loss: 0.4001 - val_mae: 0.3426\n",
      "Epoch 23/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0934 - mae: 0.1615 - val_loss: 0.4101 - val_mae: 0.3469\n",
      "Epoch 24/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0927 - mae: 0.1617 - val_loss: 0.3957 - val_mae: 0.3310\n",
      "Epoch 25/35\n",
      "101/101 [==============================] - 119s 1s/step - loss: 0.0957 - mae: 0.1606 - val_loss: 0.4026 - val_mae: 0.3217\n",
      "Epoch 26/35\n",
      "101/101 [==============================] - 119s 1s/step - loss: 0.0936 - mae: 0.1615 - val_loss: 0.3922 - val_mae: 0.3194\n",
      "Epoch 27/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0912 - mae: 0.1584 - val_loss: 0.4003 - val_mae: 0.3250\n",
      "Epoch 28/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0907 - mae: 0.1604 - val_loss: 0.4048 - val_mae: 0.3388\n",
      "Epoch 29/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0932 - mae: 0.1586 - val_loss: 0.3881 - val_mae: 0.3316\n",
      "Epoch 30/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0845 - mae: 0.1542 - val_loss: 0.4142 - val_mae: 0.3453\n",
      "Epoch 31/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0860 - mae: 0.1563 - val_loss: 0.4030 - val_mae: 0.3334\n",
      "Epoch 32/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0893 - mae: 0.1583 - val_loss: 0.4077 - val_mae: 0.3350\n",
      "Epoch 33/35\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.0811 - mae: 0.1530 - val_loss: 0.4100 - val_mae: 0.3234\n",
      "Epoch 34/35\n",
      "101/101 [==============================] - 119s 1s/step - loss: 0.0830 - mae: 0.1531 - val_loss: 0.4115 - val_mae: 0.3412\n",
      "Epoch 35/35\n",
      "101/101 [==============================] - 120s 1s/step - loss: 0.0815 - mae: 0.1514 - val_loss: 0.4160 - val_mae: 0.3403\n",
      "101/101 [==============================] - 62s 445ms/step\n",
      "44/44 [==============================] - 20s 445ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "82/82 [==============================] - 201s 1s/step - loss: 0.2033 - mae: 0.2059 - val_loss: 0.0994 - val_mae: 0.2467\n",
      "Epoch 2/35\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1600 - mae: 0.1551 - val_loss: 0.0682 - val_mae: 0.1807\n",
      "Epoch 3/35\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1576 - mae: 0.1517 - val_loss: 0.0435 - val_mae: 0.1305\n",
      "Epoch 4/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1549 - mae: 0.1472 - val_loss: 0.0405 - val_mae: 0.1345\n",
      "Epoch 5/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1500 - mae: 0.1424 - val_loss: 0.0416 - val_mae: 0.1248\n",
      "Epoch 6/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1484 - mae: 0.1382 - val_loss: 0.0397 - val_mae: 0.1252\n",
      "Epoch 7/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1465 - mae: 0.1394 - val_loss: 0.0425 - val_mae: 0.1424\n",
      "Epoch 8/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1420 - mae: 0.1370 - val_loss: 0.0396 - val_mae: 0.1271\n",
      "Epoch 9/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1393 - mae: 0.1374 - val_loss: 0.0402 - val_mae: 0.1303\n",
      "Epoch 10/35\n",
      "82/82 [==============================] - 100s 1s/step - loss: 0.1320 - mae: 0.1384 - val_loss: 0.0483 - val_mae: 0.1430\n",
      "Epoch 11/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1304 - mae: 0.1352 - val_loss: 0.0419 - val_mae: 0.1219\n",
      "Epoch 12/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1313 - mae: 0.1343 - val_loss: 0.0386 - val_mae: 0.1325\n",
      "Epoch 13/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1218 - mae: 0.1240 - val_loss: 0.0449 - val_mae: 0.1318\n",
      "Epoch 14/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1251 - mae: 0.1251 - val_loss: 0.0471 - val_mae: 0.1380\n",
      "Epoch 15/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1203 - mae: 0.1250 - val_loss: 0.0395 - val_mae: 0.1227\n",
      "Epoch 16/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1200 - mae: 0.1224 - val_loss: 0.0391 - val_mae: 0.1266\n",
      "Epoch 17/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1131 - mae: 0.1170 - val_loss: 0.0395 - val_mae: 0.1254\n",
      "Epoch 18/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1214 - mae: 0.1226 - val_loss: 0.0448 - val_mae: 0.1404\n",
      "Epoch 19/35\n",
      "82/82 [==============================] - 104s 1s/step - loss: 0.1164 - mae: 0.1189 - val_loss: 0.0385 - val_mae: 0.1274\n",
      "Epoch 20/35\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1168 - mae: 0.1203 - val_loss: 0.0409 - val_mae: 0.1268\n",
      "Epoch 21/35\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1170 - mae: 0.1216 - val_loss: 0.0422 - val_mae: 0.1351\n",
      "Epoch 22/35\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1114 - mae: 0.1160 - val_loss: 0.0409 - val_mae: 0.1278\n",
      "Epoch 23/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1129 - mae: 0.1173 - val_loss: 0.0444 - val_mae: 0.1411\n",
      "Epoch 24/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1069 - mae: 0.1145 - val_loss: 0.0419 - val_mae: 0.1345\n",
      "Epoch 25/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1080 - mae: 0.1158 - val_loss: 0.0424 - val_mae: 0.1379\n",
      "Epoch 26/35\n",
      "82/82 [==============================] - 99s 1s/step - loss: 0.1063 - mae: 0.1146 - val_loss: 0.0440 - val_mae: 0.1481\n",
      "Epoch 27/35\n",
      "82/82 [==============================] - 100s 1s/step - loss: 0.1147 - mae: 0.1193 - val_loss: 0.0448 - val_mae: 0.1347\n",
      "Epoch 28/35\n",
      "82/82 [==============================] - 100s 1s/step - loss: 0.1052 - mae: 0.1141 - val_loss: 0.0420 - val_mae: 0.1345\n",
      "Epoch 29/35\n",
      "82/82 [==============================] - 104s 1s/step - loss: 0.1009 - mae: 0.1110 - val_loss: 0.0418 - val_mae: 0.1367\n",
      "Epoch 30/35\n",
      "82/82 [==============================] - 98s 1s/step - loss: 0.1026 - mae: 0.1118 - val_loss: 0.0476 - val_mae: 0.1391\n",
      "Epoch 31/35\n",
      "82/82 [==============================] - 101s 1s/step - loss: 0.1055 - mae: 0.1154 - val_loss: 0.0427 - val_mae: 0.1358\n",
      "Epoch 32/35\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1167 - mae: 0.1290 - val_loss: 0.0435 - val_mae: 0.1366\n",
      "Epoch 33/35\n",
      "82/82 [==============================] - 104s 1s/step - loss: 0.1027 - mae: 0.1170 - val_loss: 0.0459 - val_mae: 0.1510\n",
      "Epoch 34/35\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1140 - mae: 0.1201 - val_loss: 0.0503 - val_mae: 0.1723\n",
      "Epoch 35/35\n",
      "82/82 [==============================] - 104s 1s/step - loss: 0.1055 - mae: 0.1165 - val_loss: 0.0528 - val_mae: 0.1582\n",
      "82/82 [==============================] - 77s 474ms/step\n",
      "36/36 [==============================] - 17s 476ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "101/101 [==============================] - 230s 1s/step - loss: 0.1110 - mae: 0.1857 - val_loss: 0.0683 - val_mae: 0.1976\n",
      "Epoch 2/35\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.0719 - mae: 0.1470 - val_loss: 0.0521 - val_mae: 0.1638\n",
      "Epoch 3/35\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.0693 - mae: 0.1462 - val_loss: 0.0651 - val_mae: 0.1870\n",
      "Epoch 4/35\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.0599 - mae: 0.1347 - val_loss: 0.0629 - val_mae: 0.2015\n",
      "Epoch 5/35\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.0572 - mae: 0.1342 - val_loss: 0.0705 - val_mae: 0.2179\n",
      "Epoch 6/35\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.0583 - mae: 0.1365 - val_loss: 0.0820 - val_mae: 0.2380\n",
      "Epoch 7/35\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.0553 - mae: 0.1311 - val_loss: 0.0440 - val_mae: 0.1532\n",
      "Epoch 8/35\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0528 - mae: 0.1306 - val_loss: 0.0788 - val_mae: 0.2315\n",
      "Epoch 9/35\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.0484 - mae: 0.1263 - val_loss: 0.0577 - val_mae: 0.1893\n",
      "Epoch 10/35\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.0454 - mae: 0.1237 - val_loss: 0.0722 - val_mae: 0.2143\n",
      "Epoch 11/35\n",
      "101/101 [==============================] - 146s 1s/step - loss: 0.0461 - mae: 0.1230 - val_loss: 0.1021 - val_mae: 0.2668\n",
      "Epoch 12/35\n",
      "101/101 [==============================] - 136s 1s/step - loss: 0.0446 - mae: 0.1216 - val_loss: 0.0746 - val_mae: 0.2262\n",
      "Epoch 13/35\n",
      "101/101 [==============================] - 136s 1s/step - loss: 0.0449 - mae: 0.1207 - val_loss: 0.0709 - val_mae: 0.2212\n",
      "Epoch 14/35\n",
      "101/101 [==============================] - 152s 2s/step - loss: 0.0416 - mae: 0.1181 - val_loss: 0.0689 - val_mae: 0.2115\n",
      "Epoch 15/35\n",
      "101/101 [==============================] - 154s 2s/step - loss: 0.0458 - mae: 0.1204 - val_loss: 0.0683 - val_mae: 0.2134\n",
      "Epoch 16/35\n",
      "101/101 [==============================] - 138s 1s/step - loss: 0.0415 - mae: 0.1174 - val_loss: 0.0673 - val_mae: 0.2057\n",
      "Epoch 17/35\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.0383 - mae: 0.1128 - val_loss: 0.0775 - val_mae: 0.2273\n",
      "Epoch 18/35\n",
      "101/101 [==============================] - 135s 1s/step - loss: 0.0405 - mae: 0.1127 - val_loss: 0.0817 - val_mae: 0.2303\n",
      "Epoch 19/35\n",
      "101/101 [==============================] - 134s 1s/step - loss: 0.0400 - mae: 0.1138 - val_loss: 0.0729 - val_mae: 0.2242\n",
      "Epoch 20/35\n",
      "101/101 [==============================] - 138s 1s/step - loss: 0.0383 - mae: 0.1109 - val_loss: 0.0658 - val_mae: 0.2016\n",
      "Epoch 21/35\n",
      "101/101 [==============================] - 144s 1s/step - loss: 0.0401 - mae: 0.1115 - val_loss: 0.0801 - val_mae: 0.2315\n",
      "Epoch 22/35\n",
      "101/101 [==============================] - 143s 1s/step - loss: 0.0375 - mae: 0.1105 - val_loss: 0.0791 - val_mae: 0.2223\n",
      "Epoch 23/35\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.0367 - mae: 0.1098 - val_loss: 0.0617 - val_mae: 0.1905\n",
      "Epoch 24/35\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0367 - mae: 0.1088 - val_loss: 0.0941 - val_mae: 0.2428\n",
      "Epoch 25/35\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0451 - mae: 0.1163 - val_loss: 0.1150 - val_mae: 0.2536\n",
      "Epoch 26/35\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0382 - mae: 0.1123 - val_loss: 0.0947 - val_mae: 0.2389\n",
      "Epoch 27/35\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0367 - mae: 0.1092 - val_loss: 0.0762 - val_mae: 0.2156\n",
      "Epoch 28/35\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0382 - mae: 0.1090 - val_loss: 0.0936 - val_mae: 0.2426\n",
      "Epoch 29/35\n",
      "101/101 [==============================] - 135s 1s/step - loss: 0.0369 - mae: 0.1070 - val_loss: 0.0923 - val_mae: 0.2223\n",
      "Epoch 30/35\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.0349 - mae: 0.1066 - val_loss: 0.0875 - val_mae: 0.2381\n",
      "Epoch 31/35\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.0357 - mae: 0.1069 - val_loss: 0.1248 - val_mae: 0.2860\n",
      "Epoch 32/35\n",
      "101/101 [==============================] - 149s 1s/step - loss: 0.0325 - mae: 0.1046 - val_loss: 0.0821 - val_mae: 0.2270\n",
      "Epoch 33/35\n",
      "101/101 [==============================] - 147s 1s/step - loss: 0.0312 - mae: 0.1026 - val_loss: 0.0674 - val_mae: 0.2164\n",
      "Epoch 34/35\n",
      "101/101 [==============================] - 146s 1s/step - loss: 0.0318 - mae: 0.1039 - val_loss: 0.0809 - val_mae: 0.2223\n",
      "Epoch 35/35\n",
      "101/101 [==============================] - 145s 1s/step - loss: 0.0327 - mae: 0.1035 - val_loss: 0.0710 - val_mae: 0.2045\n",
      "101/101 [==============================] - 106s 542ms/step\n",
      "44/44 [==============================] - 24s 543ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=288\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0, 1, 2, 3, 4]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    X_train= denoise_array(X_train, 0, 'bior3.3', 2, 10)\n",
    "    X_val= denoise_array(X_val, 0, 'bior3.3', 2, 10)\n",
    "    X_train = add_mp_reversed(X_train, mp_window)\n",
    "    X_val = add_mp_reversed(X_val, mp_window)\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=35, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_wavelet4/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_wavelet4/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_wavelet2/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_wavelet4/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_wavelet4/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
