{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed254beb-b30d-40dd-b1ab-1675290adaa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multihead Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e502d-6092-4e20-b503-48751d61133d",
   "metadata": {},
   "source": [
    "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536e172-1525-409d-8535-4b2c84ba389b",
   "metadata": {},
   "source": [
    "Lets test multiple attention heads, one for each input, with univariate and mutivariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd43bc1-a05c-462d-8061-561449966277",
   "metadata": {},
   "source": [
    "Lets test wavelet threshold denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc460c4b-347d-49a9-9fbd-d538bd502c34",
   "metadata": {},
   "source": [
    "Due to a slip in the matrix profile function, the matrix profile was computed in reverse in the previous iteration, this is adressed and computed normally in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cf8a4-056b-49a8-8123-cc15d8f2f71b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2243fdcb-c389-4556-be27-9373234fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import MultiHeadAttention, BatchNormalization, LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pywt\n",
    "import matrixprofile as mp\n",
    "from keras import Model\n",
    "from keras.layers import dot\n",
    "import datetime \n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd68e3ae-22e3-43af-b5e2-abdca3c87420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead):\n",
    "    X, y = list(), list()\n",
    "    example_count = int((len(sequence)/step_interval))\n",
    "    for i in range(example_count):\n",
    "        # find the end of this pattern\n",
    "        end_ix = (i*step_interval) + n_steps_in\n",
    "        out_start_ix = end_ix + n_step_lookahead -1\n",
    "        out_end_ix = end_ix + n_steps_out + n_step_lookahead -1\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[(i*step_interval):end_ix], sequence[out_start_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33011e-11aa-4433-8909-0032c7dce69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479cb03e-33f8-4df8-afe6-82b2351713ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6],\n",
       "        [3, 4, 5, 6, 7]]),\n",
       " array([[ 9],\n",
       "        [10],\n",
       "        [11],\n",
       "        [12]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To demonstrate above function\n",
    "sequence = range(0,13)\n",
    "n_steps_in = 1\n",
    "n_steps_in = 5\n",
    "n_steps_out =1\n",
    "step_interval =1\n",
    "n_step_lookahead=5\n",
    "split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0113c1-d102-4605-9fc3-542f00bd488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_data = pd.read_csv (r'C:\\Users/conal/Desktop/MCM/Practicum - Copy/data/block gas price percentile data.csv', header=0)\n",
    "percentile_data['datetime'] = pd.to_datetime(percentile_data['block_timestamp'], format = '%Y-%m-%d %H:%M:%S UTC')\n",
    "\n",
    "percentile_data = percentile_data.sort_values(by='datetime',ascending=False)\n",
    "percentile_data = percentile_data.set_index('datetime')\n",
    "percentile_data = percentile_data.resample('5T').mean()\n",
    "percentile_data = percentile_data/1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a6b649-6d02-4b5c-8892-6ca97fa10813",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum - Copy\\data\\ETH,gas,usage merged 11-26 to 05-26.csv', header=0)\n",
    "usage_data['datetime'] = pd.to_datetime(usage_data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "usage_data = usage_data.set_index('datetime')\n",
    "\n",
    "usage_data = usage_data.squeeze()\n",
    "usage_data = usage_data.astype('float')\n",
    "usage_data = usage_data.resample('5T').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49359adb-72a2-4d36-92a3-160ae229ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_data2 = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum - Copy\\data\\Contract counts 2021-11-26 to 2022-05-26.csv', header=0, index_col=0)\n",
    "usage_data2['datetime'] = pd.to_datetime(usage_data2['block_timestamp'], format = '%Y-%m-%d %H:%M:%S') \n",
    "usage_data2 = usage_data2.set_index('datetime')\n",
    "usage_data2 = usage_data2.drop(['block_timestamp'], axis=1)\n",
    "usage_data2 = usage_data2.squeeze()\n",
    "usage_data2 = usage_data2.astype('float')\n",
    "usage_data2 = usage_data2.resample('5T').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8901dad6-24e3-4393-bce8-03d4ff7aa1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = usage_data.merge(percentile_data, left_index=True, right_index=True)\n",
    "data = data.merge(usage_data2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123a9bf",
   "metadata": {},
   "source": [
    "Load data, datetime to index, downsample with left edge label, convert wei to gwei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac449a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples(data):\n",
    " \n",
    "    #Filter inputs, standardize\n",
    "    data =data[inputs]\n",
    "    scaler = StandardScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    \n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], len(inputs)))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], len(inputs)))\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5878928-c13c-4766-bcfe-2a6d1de3a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1251aaea-8a1b-423a-80c4-d88e601b2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics(yhat, y_val2):\n",
    "    #We will use validation data that has not had outleirs limited, will be a different min/max scaler as such\n",
    "    dict_indexes=[]\n",
    "    dict_dfs=[]\n",
    "    for j in range(0, n_steps_out):\n",
    "        RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "        for i in range(0, len(inputs)):  \n",
    "            pred_descaled= (scaler.inverse_transform(yhat[:,j:j+1,:].reshape(yhat.shape[0], yhat.shape[2])))[:, i:i+1]\n",
    "            groud_truth_descaled= ((scaler2.inverse_transform(y_val2[:,j:j+1,:].reshape(y_val2.shape[0], y_val2.shape[2]))))[:, i:i+1]\n",
    "            RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "            MSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=True)\n",
    "            MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "            MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "            R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "            RMSE_list.append(RMSE)\n",
    "            MAE_list.append(MAE)\n",
    "            MAPE_list.append(MAPE)\n",
    "            R2_list.append(R2)\n",
    "            MSE_list.append(MSE)\n",
    "        metrics_df = pd.DataFrame({'RMSE':RMSE_list, 'MSE':MSE_list, 'MAE':MAE_list, 'MAPE':MAPE_list, 'R2':R2_list}, index=inputs)\n",
    "        dict_dfs.append(metrics_df)\n",
    "        dict_indexes.append('Lookahead' +str(j))\n",
    "    metrics_dict = dict(zip(dict_indexes, dict_dfs))\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b29778f2-615e-4fca-878d-a1f3f4c7b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples_univariate_output(data):\n",
    " \n",
    "    #Filter inputs, standardize\n",
    "    data =data[inputs]\n",
    "    scaler = StandardScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    \n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    \n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM, filter output to only the first input\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], len(inputs)))[:,:,:1]\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], len(inputs)))[:,:,:1]\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a382560-4bf0-4dac-bc61-eb8cebeaafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics_univariate_y(yhat, y_val2):\n",
    "    #reverts standard scaling, returns dictionary of metrics for single output, for all lookaheads\n",
    "    dict_indexes=[]\n",
    "    dict_dfs=[]\n",
    "    RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "    yhat_stretched= np.repeat(yhat[:,:,0],len(inputs)).reshape(yhat.shape[0], yhat.shape[1], len(inputs))\n",
    "    y_val2_stretched= np.repeat(y_val2[:,:,0],len(inputs)).reshape(y_val2.shape[0], y_val2.shape[1], len(inputs))\n",
    "    \n",
    "    for j in range(0, n_steps_out):\n",
    "        \n",
    "        \n",
    "        pred_descaled= (scaler.inverse_transform(yhat_stretched[:, j:j+1, :].reshape(yhat_stretched.shape[0], yhat_stretched.shape[2])))[:,:1]\n",
    "        groud_truth_descaled= (scaler.inverse_transform(array([y_val2[ :, j:j+1,0].reshape(y_val2.shape[0])]*len(inputs)).transpose()))[:,:1]\n",
    "        RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "        MSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=True)\n",
    "        MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "        MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "        R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "        RMSE_list.append(RMSE)\n",
    "        MAE_list.append(MAE)\n",
    "        MAPE_list.append(MAPE)\n",
    "        R2_list.append(R2)\n",
    "        MSE_list.append(MSE)\n",
    "    metrics_df = pd.DataFrame({'RMSE':RMSE_list, 'MSE':MSE_list, 'MAE':MAE_list, 'MAPE':MAPE_list, 'R2':R2_list}, index=range(1, (n_steps_out+1)))\n",
    "\n",
    " \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6169681-82c4-4bfc-8339-abd4f990ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mp(data, window):\n",
    "    #Given 3d array, add matrix profile of (x,y,0) as new dimension; new array has dimensiosn (x,y,z+1) \n",
    "    mp_list=[]\n",
    "    for i in data[:,:,0]:\n",
    "        profile = mp.compute(i, window, n_jobs=4)['mp']\n",
    "        #we are padding the end of the sequence with the mean\n",
    "        #matrix profile is always 1 full window size smalelr than input data\n",
    "        mp_list.append(np.append(([mean(profile)]*(data.shape[1]-len(profile))),profile))\n",
    "        \n",
    "    #concatenate matrix profile data with original    \n",
    "    mp_array = np.array(mp_list).reshape(data.shape[0], data.shape[1])\n",
    "    std_array = ((mp_array-mean(mp_array))/np.std(mp_array)).reshape(data.shape[0], data.shape[1],1)\n",
    "    data = np.concatenate((data, std_array), axis=2)[:, window:, :]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d667540-d94b-41e2-8be2-2157d8e1d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def madev(d, axis=None):\n",
    "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62b0438e-807a-4952-b5c7-1b29b1dec841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoising(x, wavelet='db4', level=2, tmod=1):\n",
    "    \n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/tmod) * madev(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt(3 * np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "    return pywt.waverec(coeff, wavelet, mode='per')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d12899c2-ed58-4ebc-9a50-3471eefa885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_array(data, variable, wavelet, level, tmod):\n",
    "    denoised_examples=[]\n",
    "    for i in (data[:,:,variable]):\n",
    "        \n",
    "        denoised_examples.append(wavelet_denoising(i, wavelet=wavelet, level=level, tmod=tmod))\n",
    "        denoised_array= np.array(denoised_examples)\n",
    "        denoised_array= denoised_array.reshape(denoised_array.shape[0], denoised_array.shape[1], 1)\n",
    "    return np.concatenate((denoised_array, data[:,:,1:]),axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f4690-95e3-46ee-8934-be402e8cb94a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 layer, all variables, MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44cd8891-6f7d-4b41-9ac8-09b37e247d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(): \n",
    "    \n",
    "    #set up callback for best val loss model\n",
    "    checkpoint_filepath='./cnn/checkpoint'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    \n",
    "    n_hidden = 30\n",
    "    input_train = Input(shape=(n_steps_in, X_train.shape[2]),name='input')\n",
    "    output_train = Input(shape=( y_train.shape[1], y_train.shape[2]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    enc_head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(\n",
    "            n_hidden, activation='tanh', dropout=0.2, \n",
    "            return_state=True, return_sequences=True,name=('encoder' +str(i)))(input_train)\n",
    "\n",
    "        decoder_input = RepeatVector(y_train.shape[1], name='repeat_vector'+str(i))(encoder_last_h)\n",
    "        decoder_stack_h = LSTM(n_hidden, activation='tanh', dropout=0.2,\n",
    "         return_state=False, return_sequences=True,name=('alignment_model'+str(i)))(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "        attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2], name=('attention_dot'+str(i)))\n",
    "        attention = Activation('softmax', name='attention_activation'+str(i))(attention)\n",
    "        context = dot([attention, encoder_stack_h], axes=[2,1],name='Context'+str(i))\n",
    "        enc_head_list.append(context)\n",
    "    enc_concat_attention = Concatenate(axis=2)(enc_head_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dec_head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(\n",
    "            n_hidden, activation='tanh', dropout=0.2, \n",
    "            return_state=True, return_sequences=True,name=('decoder' +str(i)))(enc_concat_attention)\n",
    "\n",
    "        decoder_input = RepeatVector(y_train.shape[1],name='dec_repeat_vector'+str(i))(encoder_last_h)\n",
    "        decoder_stack_h = LSTM(n_hidden, activation='tanh', dropout=0.2,\n",
    "         return_state=False, return_sequences=True,name=('dec_alignment_model'+str(i)))(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "        attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2], name=('dec_attention_dot'+str(i)))\n",
    "        attention = Activation('softmax', name='dec_attention_activation'+str(i))(attention)\n",
    "        context = dot([attention, encoder_stack_h], axes=[2,1],name='dec_Context'+str(i))\n",
    "        dec_head_list.append(context)\n",
    "    dec_concat_attention = Concatenate(axis=2)(dec_head_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = TimeDistributed(Dense(y_train.shape[2]))(dec_concat_attention)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = TimeDistributed(Dense(y_train.shape[2]))(dec_concat_attention)\n",
    "\n",
    "    model = Model(inputs=input_train, outputs=out)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mae'])\n",
    "    return model, model_checkpoint_callback, checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7359bc3-edd2-4231-bc51-c7c9d551de87",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 225s 1s/step - loss: 0.2804 - mae: 0.2694 - val_loss: 0.0563 - val_mae: 0.1682\n",
      "Epoch 2/15\n",
      "  2/101 [..............................] - ETA: 1:39 - loss: 0.1297 - mae: 0.2364"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_236/3474915892.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mtrain_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=288\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0,1,2,3,4]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    #X_train= denoise_array(X_train, 0, 'db4', 2, 3)\n",
    "    #X_val= denoise_array(X_val, 0, 'db4', 2, 3)\n",
    "    X_train = add_mp(X_train, mp_window)\n",
    "    X_val = add_mp(X_val, mp_window)\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_forward_10_lookahead/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_forward_10_lookahead/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_forward_10_lookahead/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_forward_10_lookahead/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_forward_10_lookahead/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd87a5-f224-4381-a779-47c36414e9cf",
   "metadata": {},
   "source": [
    "Loop was stopped during the final month of training; run for final month only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e8f294b-8d0d-4dcc-a969-dd367e7620e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 237s 1s/step - loss: 0.1244 - mae: 0.1952 - val_loss: 0.0493 - val_mae: 0.1550\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0780 - mae: 0.1521 - val_loss: 0.0457 - val_mae: 0.1560\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0641 - mae: 0.1420 - val_loss: 0.0397 - val_mae: 0.1283\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0664 - mae: 0.1384 - val_loss: 0.0547 - val_mae: 0.1836\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0557 - mae: 0.1340 - val_loss: 0.0474 - val_mae: 0.1600\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0508 - mae: 0.1298 - val_loss: 0.0507 - val_mae: 0.1733\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0489 - mae: 0.1279 - val_loss: 0.0521 - val_mae: 0.1786\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0502 - mae: 0.1291 - val_loss: 0.0470 - val_mae: 0.1623\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0487 - mae: 0.1261 - val_loss: 0.0519 - val_mae: 0.1777\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0475 - mae: 0.1251 - val_loss: 0.0526 - val_mae: 0.1754\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 130s 1s/step - loss: 0.0435 - mae: 0.1212 - val_loss: 0.0781 - val_mae: 0.2358\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0529 - mae: 0.1241 - val_loss: 0.0759 - val_mae: 0.2289\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 130s 1s/step - loss: 0.0430 - mae: 0.1206 - val_loss: 0.0635 - val_mae: 0.1916\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0496 - mae: 0.1203 - val_loss: 0.0602 - val_mae: 0.1813\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0415 - mae: 0.1152 - val_loss: 0.0759 - val_mae: 0.2126\n",
      "101/101 [==============================] - 67s 478ms/step\n",
      "44/44 [==============================] - 21s 478ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=288\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [4]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    #X_train= denoise_array(X_train, 0, 'db4', 2, 3)\n",
    "    #X_val= denoise_array(X_val, 0, 'db4', 2, 3)\n",
    "    X_train = add_mp(X_train, mp_window)\n",
    "    X_val = add_mp(X_val, mp_window)\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_forward_10_lookahead/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_forward_10_lookaheadm4/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_forward_10_lookaheadm4/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_forward_10_lookaheadm4/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_forward_10_lookaheadm4/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea45e4-fcec-4dc7-9e46-c09888f15ffb",
   "metadata": {},
   "source": [
    "Append month 4 to rest of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "448051f8-ba31-45ca-af3f-46168513bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m4 = np.load('2_Att_layer_MP_forward_10_lookaheadm4/training_metrics.npy',allow_pickle=True)\n",
    "val_m4 = np.load(\"2_Att_layer_MP_forward_10_lookaheadm4/val_metrics.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4d39e5b-9827-49f8-9610-3cdca76c1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m0_3 = np.load('2_Att_layer_MP_forward_10_lookahead/training_metrics.npy',allow_pickle=True)\n",
    "val_m0_3 = np.load(\"2_Att_layer_MP_forward_10_lookahead/val_metrics.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b87a8601-f098-4c5c-956a-3c90e6dc82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics=np.concatenate((train_m0_3, train_m4), axis=0)\n",
    "val_metrics = np.concatenate((val_m0_3, val_m4), axis=0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a6539b7-e49f-45ac-b1ef-101186b43124",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"2_Att_layer_MP_forward_10_lookahead/training_metrics_all.npy\", train_metrics)\n",
    "np.save(\"2_Att_layer_MP_forward_10_lookahead/val_metrics_all.npy\", val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf92d4f5-603d-4bb8-bc3b-a7d6d65ddb85",
   "metadata": {},
   "source": [
    "## DB4 wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f7cb4d8-9c78-4a5f-b9f0-14dc13185b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 228s 1s/step - loss: 0.2912 - mae: 0.2796 - val_loss: 0.0590 - val_mae: 0.1783\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 137s 1s/step - loss: 0.2296 - mae: 0.2217 - val_loss: 0.0574 - val_mae: 0.1551\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 147s 1s/step - loss: 0.2204 - mae: 0.2119 - val_loss: 0.0562 - val_mae: 0.1501\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 148s 1s/step - loss: 0.2155 - mae: 0.2095 - val_loss: 0.0913 - val_mae: 0.2228\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 150s 1s/step - loss: 0.2086 - mae: 0.2067 - val_loss: 0.0543 - val_mae: 0.1581\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 149s 1s/step - loss: 0.2005 - mae: 0.2022 - val_loss: 0.0632 - val_mae: 0.1705\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 148s 1s/step - loss: 0.1986 - mae: 0.2012 - val_loss: 0.0623 - val_mae: 0.1678\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 148s 1s/step - loss: 0.1915 - mae: 0.1955 - val_loss: 0.0719 - val_mae: 0.1837\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 145s 1s/step - loss: 0.1904 - mae: 0.2017 - val_loss: 0.0775 - val_mae: 0.1936\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 137s 1s/step - loss: 0.1934 - mae: 0.1934 - val_loss: 0.0721 - val_mae: 0.1809\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 138s 1s/step - loss: 0.1875 - mae: 0.1927 - val_loss: 0.0678 - val_mae: 0.1771\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 144s 1s/step - loss: 0.1832 - mae: 0.1883 - val_loss: 0.0800 - val_mae: 0.1897\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 150s 1s/step - loss: 0.1756 - mae: 0.1841 - val_loss: 0.0698 - val_mae: 0.1740\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 150s 1s/step - loss: 0.1748 - mae: 0.1817 - val_loss: 0.0844 - val_mae: 0.2017\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 130s 1s/step - loss: 0.1735 - mae: 0.1826 - val_loss: 0.0831 - val_mae: 0.2021\n",
      "101/101 [==============================] - 79s 482ms/step\n",
      "44/44 [==============================] - 21s 482ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/107 [==============================] - 237s 1s/step - loss: 0.6606 - mae: 0.4546 - val_loss: 0.4578 - val_mae: 0.4465\n",
      "Epoch 2/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.5496 - mae: 0.3874 - val_loss: 0.3988 - val_mae: 0.3655\n",
      "Epoch 3/15\n",
      "107/107 [==============================] - 136s 1s/step - loss: 0.5374 - mae: 0.3793 - val_loss: 0.4337 - val_mae: 0.4236\n",
      "Epoch 4/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.5095 - mae: 0.3716 - val_loss: 0.4339 - val_mae: 0.4038\n",
      "Epoch 5/15\n",
      "107/107 [==============================] - 136s 1s/step - loss: 0.4903 - mae: 0.3648 - val_loss: 0.4502 - val_mae: 0.4031\n",
      "Epoch 6/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4632 - mae: 0.3559 - val_loss: 0.4793 - val_mae: 0.4754\n",
      "Epoch 7/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4567 - mae: 0.3578 - val_loss: 0.5272 - val_mae: 0.4873\n",
      "Epoch 8/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4448 - mae: 0.3587 - val_loss: 0.5598 - val_mae: 0.5432\n",
      "Epoch 9/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4273 - mae: 0.3438 - val_loss: 0.5560 - val_mae: 0.5415\n",
      "Epoch 10/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4344 - mae: 0.3458 - val_loss: 0.5051 - val_mae: 0.4928\n",
      "Epoch 11/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4139 - mae: 0.3398 - val_loss: 0.6602 - val_mae: 0.6165\n",
      "Epoch 12/15\n",
      "107/107 [==============================] - 136s 1s/step - loss: 0.4150 - mae: 0.3418 - val_loss: 0.7704 - val_mae: 0.6489\n",
      "Epoch 13/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.3944 - mae: 0.3297 - val_loss: 0.4926 - val_mae: 0.4495\n",
      "Epoch 14/15\n",
      "107/107 [==============================] - 136s 1s/step - loss: 0.3926 - mae: 0.3272 - val_loss: 0.5314 - val_mae: 0.5316\n",
      "Epoch 15/15\n",
      "107/107 [==============================] - 136s 1s/step - loss: 0.3845 - mae: 0.3228 - val_loss: 0.5554 - val_mae: 0.5356\n",
      "107/107 [==============================] - 68s 478ms/step\n",
      "46/46 [==============================] - 22s 475ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 221s 1s/step - loss: 0.1699 - mae: 0.2372 - val_loss: 0.3467 - val_mae: 0.2527\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1486 - mae: 0.2100 - val_loss: 0.3606 - val_mae: 0.2573\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1426 - mae: 0.2078 - val_loss: 0.3822 - val_mae: 0.2634\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1335 - mae: 0.1990 - val_loss: 0.3509 - val_mae: 0.2809\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1283 - mae: 0.1965 - val_loss: 0.3537 - val_mae: 0.3027\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1229 - mae: 0.1920 - val_loss: 0.3440 - val_mae: 0.2707\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1173 - mae: 0.1868 - val_loss: 0.3690 - val_mae: 0.2952\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1151 - mae: 0.1834 - val_loss: 0.3788 - val_mae: 0.3278\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.1140 - mae: 0.1841 - val_loss: 0.3843 - val_mae: 0.3432\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1136 - mae: 0.1817 - val_loss: 0.3641 - val_mae: 0.2854\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.1099 - mae: 0.1779 - val_loss: 0.3551 - val_mae: 0.2922\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.1105 - mae: 0.1778 - val_loss: 0.3813 - val_mae: 0.3266\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.1083 - mae: 0.1754 - val_loss: 0.3744 - val_mae: 0.3004\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1068 - mae: 0.1735 - val_loss: 0.3790 - val_mae: 0.3016\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1062 - mae: 0.1718 - val_loss: 0.3762 - val_mae: 0.3099\n",
      "101/101 [==============================] - 65s 472ms/step\n",
      "44/44 [==============================] - 21s 472ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82/82 [==============================] - 199s 1s/step - loss: 0.2155 - mae: 0.2137 - val_loss: 0.0587 - val_mae: 0.1524\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 109s 1s/step - loss: 0.1576 - mae: 0.1456 - val_loss: 0.0437 - val_mae: 0.1366\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1550 - mae: 0.1441 - val_loss: 0.0486 - val_mae: 0.1692\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1498 - mae: 0.1438 - val_loss: 0.0532 - val_mae: 0.1745\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1469 - mae: 0.1390 - val_loss: 0.0452 - val_mae: 0.1419\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1412 - mae: 0.1345 - val_loss: 0.0439 - val_mae: 0.1412\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 104s 1s/step - loss: 0.1365 - mae: 0.1318 - val_loss: 0.0415 - val_mae: 0.1331\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1406 - mae: 0.1407 - val_loss: 0.0439 - val_mae: 0.1399\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1315 - mae: 0.1347 - val_loss: 0.0455 - val_mae: 0.1414\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 104s 1s/step - loss: 0.1285 - mae: 0.1340 - val_loss: 0.0502 - val_mae: 0.1722\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1368 - mae: 0.1349 - val_loss: 0.0426 - val_mae: 0.1426\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1247 - mae: 0.1262 - val_loss: 0.0442 - val_mae: 0.1439\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1260 - mae: 0.1283 - val_loss: 0.0420 - val_mae: 0.1410\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1215 - mae: 0.1239 - val_loss: 0.0428 - val_mae: 0.1410\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1212 - mae: 0.1211 - val_loss: 0.0464 - val_mae: 0.1510\n",
      "82/82 [==============================] - 56s 477ms/step\n",
      "36/36 [==============================] - 17s 477ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 232s 1s/step - loss: 0.1322 - mae: 0.2009 - val_loss: 0.0413 - val_mae: 0.1294\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0924 - mae: 0.1637 - val_loss: 0.0413 - val_mae: 0.1360\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0699 - mae: 0.1458 - val_loss: 0.0437 - val_mae: 0.1469\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0651 - mae: 0.1449 - val_loss: 0.0419 - val_mae: 0.1280\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0558 - mae: 0.1356 - val_loss: 0.0431 - val_mae: 0.1480\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 132s 1s/step - loss: 0.0574 - mae: 0.1351 - val_loss: 0.0399 - val_mae: 0.1221\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0549 - mae: 0.1329 - val_loss: 0.0448 - val_mae: 0.1540\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0510 - mae: 0.1276 - val_loss: 0.0403 - val_mae: 0.1340\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.0500 - mae: 0.1273 - val_loss: 0.0488 - val_mae: 0.1687\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0459 - mae: 0.1240 - val_loss: 0.0445 - val_mae: 0.1507\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.0474 - mae: 0.1254 - val_loss: 0.0490 - val_mae: 0.1694\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0577 - mae: 0.1293 - val_loss: 0.0488 - val_mae: 0.1618\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0436 - mae: 0.1201 - val_loss: 0.0647 - val_mae: 0.2103\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0459 - mae: 0.1238 - val_loss: 0.0498 - val_mae: 0.1746\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0429 - mae: 0.1195 - val_loss: 0.0528 - val_mae: 0.1802\n",
      "101/101 [==============================] - 66s 477ms/step\n",
      "44/44 [==============================] - 21s 469ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=288\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0, 1, 2, 3, 4]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    X_train= denoise_array(X_train, 0, 'db4', 2, 3)\n",
    "    X_val= denoise_array(X_val, 0, 'db4', 2, 3)\n",
    "    X_train = add_mp(X_train, mp_window)\n",
    "    X_val = add_mp(X_val, mp_window)\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_forward_10_lookahead_db4/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_forward_10_lookahead_db4/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_forward_10_lookahead_db4/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_forward_10_lookahead_db4/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_forward_10_lookahead_db4/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3199aea-e95c-4ab7-9bc1-9777996950d5",
   "metadata": {},
   "source": [
    "## Bior wavelet, less aggresive denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c871c698-bc48-41fc-b751-4e4bd613f371",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 241s 1s/step - loss: 0.2824 - mae: 0.2726 - val_loss: 0.0591 - val_mae: 0.1697\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.2260 - mae: 0.2142 - val_loss: 0.0562 - val_mae: 0.1661\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 130s 1s/step - loss: 0.2169 - mae: 0.2112 - val_loss: 0.0543 - val_mae: 0.1611\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.2159 - mae: 0.2147 - val_loss: 0.0589 - val_mae: 0.1652\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.2005 - mae: 0.2024 - val_loss: 0.0659 - val_mae: 0.1761\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.1957 - mae: 0.1992 - val_loss: 0.1076 - val_mae: 0.2549\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 131s 1s/step - loss: 0.1918 - mae: 0.1983 - val_loss: 0.0775 - val_mae: 0.1989\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 130s 1s/step - loss: 0.1884 - mae: 0.1944 - val_loss: 0.1044 - val_mae: 0.2365\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1890 - mae: 0.1951 - val_loss: 0.0907 - val_mae: 0.2094\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.1863 - mae: 0.1954 - val_loss: 0.0970 - val_mae: 0.2193\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1798 - mae: 0.1866 - val_loss: 0.1021 - val_mae: 0.2192\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.1762 - mae: 0.1854 - val_loss: 0.1044 - val_mae: 0.2282\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1735 - mae: 0.1843 - val_loss: 0.0814 - val_mae: 0.1856\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1732 - mae: 0.1833 - val_loss: 0.0736 - val_mae: 0.1815\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.1725 - mae: 0.1845 - val_loss: 0.0864 - val_mae: 0.1931\n",
      "101/101 [==============================] - 66s 464ms/step\n",
      "44/44 [==============================] - 20s 458ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/107 [==============================] - 254s 1s/step - loss: 0.6626 - mae: 0.4537 - val_loss: 0.4303 - val_mae: 0.4124\n",
      "Epoch 2/15\n",
      "107/107 [==============================] - 137s 1s/step - loss: 0.5447 - mae: 0.3838 - val_loss: 0.4378 - val_mae: 0.4078\n",
      "Epoch 3/15\n",
      "107/107 [==============================] - 136s 1s/step - loss: 0.5370 - mae: 0.3869 - val_loss: 0.4781 - val_mae: 0.4547\n",
      "Epoch 4/15\n",
      "107/107 [==============================] - 136s 1s/step - loss: 0.5050 - mae: 0.3732 - val_loss: 0.5211 - val_mae: 0.5040\n",
      "Epoch 5/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4907 - mae: 0.3719 - val_loss: 0.4499 - val_mae: 0.4045\n",
      "Epoch 6/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4776 - mae: 0.3672 - val_loss: 0.4658 - val_mae: 0.4472\n",
      "Epoch 7/15\n",
      "107/107 [==============================] - 137s 1s/step - loss: 0.4689 - mae: 0.3584 - val_loss: 0.4814 - val_mae: 0.4666\n",
      "Epoch 8/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4372 - mae: 0.3467 - val_loss: 0.5408 - val_mae: 0.5129\n",
      "Epoch 9/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4230 - mae: 0.3404 - val_loss: 0.4988 - val_mae: 0.4669\n",
      "Epoch 10/15\n",
      "107/107 [==============================] - 134s 1s/step - loss: 0.4110 - mae: 0.3352 - val_loss: 0.5310 - val_mae: 0.4941\n",
      "Epoch 11/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.4032 - mae: 0.3312 - val_loss: 0.5103 - val_mae: 0.4471\n",
      "Epoch 12/15\n",
      "107/107 [==============================] - 134s 1s/step - loss: 0.4079 - mae: 0.3356 - val_loss: 0.5070 - val_mae: 0.4551\n",
      "Epoch 13/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.3996 - mae: 0.3308 - val_loss: 0.6836 - val_mae: 0.6214\n",
      "Epoch 14/15\n",
      "107/107 [==============================] - 136s 1s/step - loss: 0.3820 - mae: 0.3205 - val_loss: 0.6636 - val_mae: 0.6041\n",
      "Epoch 15/15\n",
      "107/107 [==============================] - 134s 1s/step - loss: 0.3741 - mae: 0.3204 - val_loss: 0.6031 - val_mae: 0.5527\n",
      "107/107 [==============================] - 70s 464ms/step\n",
      "46/46 [==============================] - 21s 467ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 244s 1s/step - loss: 0.1744 - mae: 0.2427 - val_loss: 0.3644 - val_mae: 0.2639\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1513 - mae: 0.2126 - val_loss: 0.3707 - val_mae: 0.2527\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1442 - mae: 0.2068 - val_loss: 0.3627 - val_mae: 0.2617\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1383 - mae: 0.2023 - val_loss: 0.3799 - val_mae: 0.2759\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1340 - mae: 0.1984 - val_loss: 0.3870 - val_mae: 0.3157\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.1291 - mae: 0.1951 - val_loss: 0.3922 - val_mae: 0.2823\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.1239 - mae: 0.1912 - val_loss: 0.3667 - val_mae: 0.2868\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1210 - mae: 0.1884 - val_loss: 0.3884 - val_mae: 0.3250\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1203 - mae: 0.1896 - val_loss: 0.3891 - val_mae: 0.3023\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1141 - mae: 0.1837 - val_loss: 0.3738 - val_mae: 0.3087\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.1140 - mae: 0.1821 - val_loss: 0.4166 - val_mae: 0.3602\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1109 - mae: 0.1791 - val_loss: 0.3822 - val_mae: 0.3097\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.1086 - mae: 0.1761 - val_loss: 0.3893 - val_mae: 0.3478\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.1069 - mae: 0.1747 - val_loss: 0.4315 - val_mae: 0.3866\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1055 - mae: 0.1727 - val_loss: 0.4053 - val_mae: 0.3441\n",
      "101/101 [==============================] - 66s 467ms/step\n",
      "44/44 [==============================] - 21s 486ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82/82 [==============================] - 222s 2s/step - loss: 0.2028 - mae: 0.2018 - val_loss: 0.0683 - val_mae: 0.1718\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1616 - mae: 0.1577 - val_loss: 0.0442 - val_mae: 0.1429\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1518 - mae: 0.1431 - val_loss: 0.0506 - val_mae: 0.1485\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1484 - mae: 0.1406 - val_loss: 0.0580 - val_mae: 0.1783\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 104s 1s/step - loss: 0.1455 - mae: 0.1409 - val_loss: 0.0455 - val_mae: 0.1520\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1413 - mae: 0.1407 - val_loss: 0.0509 - val_mae: 0.1539\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1386 - mae: 0.1378 - val_loss: 0.0464 - val_mae: 0.1443\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 104s 1s/step - loss: 0.1312 - mae: 0.1352 - val_loss: 0.0461 - val_mae: 0.1457\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 105s 1s/step - loss: 0.1273 - mae: 0.1295 - val_loss: 0.0436 - val_mae: 0.1328\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1282 - mae: 0.1269 - val_loss: 0.0437 - val_mae: 0.1353\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1202 - mae: 0.1241 - val_loss: 0.0419 - val_mae: 0.1345\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 102s 1s/step - loss: 0.1245 - mae: 0.1249 - val_loss: 0.0430 - val_mae: 0.1285\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1215 - mae: 0.1246 - val_loss: 0.0436 - val_mae: 0.1355\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1293 - mae: 0.1281 - val_loss: 0.0600 - val_mae: 0.1630\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 103s 1s/step - loss: 0.1225 - mae: 0.1226 - val_loss: 0.0420 - val_mae: 0.1284\n",
      "82/82 [==============================] - 57s 476ms/step\n",
      "36/36 [==============================] - 17s 473ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 242s 1s/step - loss: 0.1121 - mae: 0.1895 - val_loss: 0.0554 - val_mae: 0.1776\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 125s 1s/step - loss: 0.0715 - mae: 0.1518 - val_loss: 0.0493 - val_mae: 0.1507\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.0680 - mae: 0.1455 - val_loss: 0.0602 - val_mae: 0.1985\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0596 - mae: 0.1396 - val_loss: 0.0529 - val_mae: 0.1776\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0547 - mae: 0.1335 - val_loss: 0.0441 - val_mae: 0.1491\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0582 - mae: 0.1353 - val_loss: 0.0429 - val_mae: 0.1485\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0521 - mae: 0.1314 - val_loss: 0.0754 - val_mae: 0.2365\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0485 - mae: 0.1297 - val_loss: 0.0557 - val_mae: 0.1845\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0446 - mae: 0.1234 - val_loss: 0.0509 - val_mae: 0.1718\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0435 - mae: 0.1223 - val_loss: 0.0692 - val_mae: 0.2180\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.0442 - mae: 0.1204 - val_loss: 0.0712 - val_mae: 0.2226\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 128s 1s/step - loss: 0.0470 - mae: 0.1241 - val_loss: 0.0524 - val_mae: 0.1788\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.0442 - mae: 0.1205 - val_loss: 0.0517 - val_mae: 0.1721\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 127s 1s/step - loss: 0.0423 - mae: 0.1162 - val_loss: 0.0730 - val_mae: 0.2167\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.0405 - mae: 0.1149 - val_loss: 0.0701 - val_mae: 0.2195\n",
      "101/101 [==============================] - 67s 476ms/step\n",
      "44/44 [==============================] - 21s 473ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window=288\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0, 1, 2, 3, 4]:\n",
    "    n_steps_in = 4032+288\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    X_train= denoise_array(X_train, 0, 'bior3.3', 2, 10)\n",
    "    X_val= denoise_array(X_val, 0, 'bior3.3', 2, 10)\n",
    "    X_train = add_mp(X_train, mp_window)\n",
    "    X_val = add_mp(X_val, mp_window)\n",
    "    \n",
    "   \n",
    "    \n",
    "    n_steps_in = 4032\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback, checkpoint_filepath = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "    model.save_weights(('2_Att_layer_MP_fwd_bior3.3/Month' +str(month)))\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)  \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "    pd.DataFrame(train_loss_list).to_csv('2_Att_layer_MP_fwd_bior3.3/train_loss.csv')\n",
    "    pd.DataFrame(val_loss_list).to_csv('2_Att_layer_MP_fwd_bior3.3/val_loss.csv')\n",
    "    np.save(\"2_Att_layer_MP_fwd_bior3.3/training_metrics.npy\", training_metrics_dicts)\n",
    "    np.save(\"2_Att_layer_MP_fwd_bior3.3/val_metrics.npy\", valdiation_metrics_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
