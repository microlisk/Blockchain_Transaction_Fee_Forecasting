{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed254beb-b30d-40dd-b1ab-1675290adaa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37e93b-6745-46e3-9a97-d09555f575fc",
   "metadata": {},
   "source": [
    "Lets try a model with two 1-D convolutional layers feeding into an LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cf8a4-056b-49a8-8123-cc15d8f2f71b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2243fdcb-c389-4556-be27-9373234fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras import callbacks\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7eee058-7ceb-4541-b2b4-2b9426ee3aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', 'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/HostX64/x64/cl.exe'), ('cuda_compute_capabilities', ['sm_35', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']), ('cuda_version', '64_112'), ('cudart_dll_name', 'cudart64_112.dll'), ('cudnn_dll_name', 'cudnn64_8.dll'), ('cudnn_version', '64_8'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False), ('msvcp_dll_names', 'msvcp140.dll,msvcp140_1.dll'), ('nvcuda_dll_name', 'nvcuda.dll')])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.python.platform.build_info as build\n",
    "print(build.build_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd68e3ae-22e3-43af-b5e2-abdca3c87420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead):\n",
    "    X, y = list(), list()\n",
    "    example_count = int((len(sequence)/step_interval))\n",
    "    for i in range(example_count):\n",
    "        # find the end of this pattern\n",
    "        end_ix = (i*step_interval) + n_steps_in\n",
    "        out_start_ix = end_ix + n_step_lookahead -1\n",
    "        out_end_ix = end_ix + n_steps_out + n_step_lookahead -1\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[(i*step_interval):end_ix], sequence[out_start_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479cb03e-33f8-4df8-afe6-82b2351713ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6],\n",
       "        [3, 4, 5, 6, 7]]),\n",
       " array([[ 9],\n",
       "        [10],\n",
       "        [11],\n",
       "        [12]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To demonstrate above function\n",
    "sequence = range(0,13)\n",
    "n_steps_in = 1\n",
    "n_steps_in = 5\n",
    "n_steps_out =1\n",
    "step_interval =1\n",
    "n_step_lookahead=5\n",
    "split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0113c1-d102-4605-9fc3-542f00bd488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_data = pd.read_csv (r'C:\\Users/conal/Desktop/MCM/Practicum - Copy/data/block gas price percentile data.csv', header=0)\n",
    "percentile_data['datetime'] = pd.to_datetime(percentile_data['block_timestamp'], format = '%Y-%m-%d %H:%M:%S UTC')\n",
    "\n",
    "percentile_data = percentile_data.sort_values(by='datetime',ascending=False)\n",
    "percentile_data = percentile_data.set_index('datetime')\n",
    "#percentile_data = percentile_data.resample('5T').mean()\n",
    "#percentile_data = percentile_data/1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be40fcef-ef59-4feb-914b-bc2c5ad755b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953336"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(percentile_data[:'2022-04-27 00:00:00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a6b649-6d02-4b5c-8892-6ca97fa10813",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum - Copy\\data\\ETH,gas,usage merged 11-26 to 05-26.csv', header=0)\n",
    "usage_data['datetime'] = pd.to_datetime(usage_data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "usage_data = usage_data.set_index('datetime')\n",
    "\n",
    "usage_data = usage_data.squeeze()\n",
    "usage_data = usage_data.astype('float')\n",
    "usage_data = usage_data.resample('5T').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b30fac-ab74-4d74-802d-079d808a93b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49359adb-72a2-4d36-92a3-160ae229ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_data2 = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum - Copy\\data\\Contract counts 2021-11-26 to 2022-05-26.csv', header=0, index_col=0)\n",
    "usage_data2['datetime'] = pd.to_datetime(usage_data2['block_timestamp'], format = '%Y-%m-%d %H:%M:%S') \n",
    "usage_data2 = usage_data2.set_index('datetime')\n",
    "usage_data2 = usage_data2.drop(['block_timestamp'], axis=1)\n",
    "usage_data2 = usage_data2.squeeze()\n",
    "usage_data2 = usage_data2.astype('float')\n",
    "usage_data2 = usage_data2.resample('5T').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8901dad6-24e3-4393-bce8-03d4ff7aa1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = usage_data.merge(percentile_data, left_index=True, right_index=True)\n",
    "data = data.merge(usage_data2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123a9bf",
   "metadata": {},
   "source": [
    "Load data, datetime to index, downsample with left edge label, convert wei to gwei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac449a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples(data):\n",
    " \n",
    "    #Filter inputs, standardize\n",
    "    data =data[inputs]\n",
    "    scaler = StandardScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    \n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], len(inputs)))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], len(inputs)))\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046086f6-7346-4550-8d58-ba108d69ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "    \n",
    "    checkpoint_filepath='./cnn/checkpoint'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=9, activation='tanh', input_shape=(n_steps_in, len(inputs))))\n",
    "    model.add(Conv1D(filters=64, kernel_size=11, activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    model.add(LSTM(200, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='tanh')))\n",
    "    model.add(TimeDistributed(Dense(len(inputs))))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model, model_checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5878928-c13c-4766-bcfe-2a6d1de3a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251aaea-8a1b-423a-80c4-d88e601b2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics(yhat, y_val2):\n",
    "    #We will use validation data that has not had outleirs limited, will be a different min/max scaler as such\n",
    "    dict_indexes=[]\n",
    "    dict_dfs=[]\n",
    "    for j in range(0, n_steps_out):\n",
    "        RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "        for i in range(0, len(inputs)):  \n",
    "            pred_descaled= (scaler.inverse_transform(yhat[:,j:j+1,:].reshape(yhat.shape[0], yhat.shape[2])))[:, i:i+1]\n",
    "            groud_truth_descaled= ((scaler.inverse_transform(y_val2[:,j:j+1,:].reshape(y_val2.shape[0], y_val2.shape[2]))))[:, i:i+1]\n",
    "            RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "            MSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=True)\n",
    "            MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "            MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "            R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "            RMSE_list.append(RMSE)\n",
    "            MAE_list.append(MAE)\n",
    "            MAPE_list.append(MAPE)\n",
    "            R2_list.append(R2)\n",
    "            MSE_list.append(MSE)\n",
    "        metrics_df = pd.DataFrame({'RMSE':RMSE_list, 'MSE':MSE_list, 'MAE':MAE_list, 'MAPE':MAPE_list, 'R2':R2_list}, index=inputs)\n",
    "        dict_dfs.append(metrics_df)\n",
    "        dict_indexes.append('Lookahead' +str(j))\n",
    "    metrics_dict = dict(zip(dict_indexes, dict_dfs))\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872e19c-41fd-4aa1-a3c0-bf9598fbd365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples_univariate_output(data):\n",
    " \n",
    "    #Filter inputs, standardize\n",
    "    data =data[inputs]\n",
    "    scaler = StandardScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    \n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], len(inputs)))[:,:,:1]\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], len(inputs)))[:,:,:1]\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17abc08-deb1-47a6-8352-8f2b2f1a0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics_univariate_y(yhat, y_val2):\n",
    "    #We will use validation data that has not had outleirs limited, will be a different min/max scaler as such\n",
    "    dict_indexes=[]\n",
    "    dict_dfs=[]\n",
    "    RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "    for j in range(0, n_steps_out):\n",
    "        pred_descaled= (scaler.inverse_transform(yhat[:, j:j+1].reshape(yhat.shape[0], yhat.shape[2])))[:,:1]\n",
    "        groud_truth_descaled= (scaler.inverse_transform(array([y_val2[ :, j:j+1].reshape(y_val2.shape[0])]*len(inputs)).transpose()))[:,:1]\n",
    "        RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "        MSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=True)\n",
    "        MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "        MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "        R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "        RMSE_list.append(RMSE)\n",
    "        MAE_list.append(MAE)\n",
    "        MAPE_list.append(MAPE)\n",
    "        R2_list.append(R2)\n",
    "        MSE_list.append(MSE)\n",
    "    metrics_df = pd.DataFrame({'RMSE':RMSE_list, 'MSE':MSE_list, 'MAE':MAE_list, 'MAPE':MAPE_list, 'R2':R2_list}, index=range(1, (n_steps_out+1)))\n",
    "\n",
    " \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19565781-e265-467d-a122-883125f0f4a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lets optimize for min gas price only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0a08e01-1aa8-4f23-827e-d2c0eab22503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "107/107 [==============================] - 46s 413ms/step - loss: 0.5260 - val_loss: 0.1156\n",
      "Epoch 2/5\n",
      "107/107 [==============================] - 43s 403ms/step - loss: 0.4697 - val_loss: 0.1101\n",
      "Epoch 3/5\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.4629 - val_loss: 0.1083\n",
      "Epoch 4/5\n",
      "107/107 [==============================] - 8s 77ms/step - loss: 0.4635 - val_loss: 0.1151\n",
      "Epoch 5/5\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.4643 - val_loss: 0.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn1/Month0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn1/Month0\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001AC05FBA340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 3s 25ms/step\n",
      "46/46 [==============================] - 2s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "114/114 [==============================] - 47s 399ms/step - loss: 0.8815 - val_loss: 0.6749\n",
      "Epoch 2/5\n",
      "114/114 [==============================] - 9s 76ms/step - loss: 0.7155 - val_loss: 0.6970\n",
      "Epoch 3/5\n",
      "114/114 [==============================] - 44s 388ms/step - loss: 0.6567 - val_loss: 0.5560\n",
      "Epoch 4/5\n",
      "114/114 [==============================] - 9s 76ms/step - loss: 0.6516 - val_loss: 0.7080\n",
      "Epoch 5/5\n",
      "114/114 [==============================] - 9s 76ms/step - loss: 0.6983 - val_loss: 0.7540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn1/Month1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn1/Month1\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001AC0813F5E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 3s 25ms/step\n",
      "49/49 [==============================] - 1s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "108/108 [==============================] - 49s 432ms/step - loss: 0.3443 - val_loss: 0.4840\n",
      "Epoch 2/5\n",
      "108/108 [==============================] - 44s 407ms/step - loss: 0.2965 - val_loss: 0.4706\n",
      "Epoch 3/5\n",
      "108/108 [==============================] - 44s 406ms/step - loss: 0.2895 - val_loss: 0.4342\n",
      "Epoch 4/5\n",
      "108/108 [==============================] - 9s 77ms/step - loss: 0.3148 - val_loss: 0.6047\n",
      "Epoch 5/5\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.2817 - val_loss: 0.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn1/Month2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn1/Month2\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001AC001C7AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 3s 26ms/step\n",
      "46/46 [==============================] - 1s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "89/89 [==============================] - 46s 494ms/step - loss: 0.3362 - val_loss: 0.0752\n",
      "Epoch 2/5\n",
      "89/89 [==============================] - 7s 71ms/step - loss: 0.2472 - val_loss: 0.0890\n",
      "Epoch 3/5\n",
      "89/89 [==============================] - 6s 70ms/step - loss: 0.2488 - val_loss: 0.0810\n",
      "Epoch 4/5\n",
      "89/89 [==============================] - 6s 71ms/step - loss: 0.2473 - val_loss: 0.0916\n",
      "Epoch 5/5\n",
      "89/89 [==============================] - 7s 74ms/step - loss: 0.2503 - val_loss: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn1/Month3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn1/Month3\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001AC0276EF40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 3s 26ms/step\n",
      "38/38 [==============================] - 1s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/108 [..............................] - ETA: 4:21 - loss: 0.4424"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12852/3610813354.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mtrain_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mval_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032\n",
    "n_steps_out = 5\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "for month in [0, 1, 2, 3, 4]:\n",
    "    n_step_lookahead = 1\n",
    "    start_date=Start_dates[month]\n",
    "    end_date=end_dates[month]\n",
    "    X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    model, model_checkpoint_callback = LSTM_model()\n",
    "    train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=5, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "    train_loss_list.append(train_history.history['loss'])\n",
    "    val_loss_list.append(train_history.history['val_loss'])\n",
    "\n",
    "    \n",
    "    yhat_train=model.predict(X_train, verbose=1)\n",
    "    yhat_val = model.predict(X_val, verbose=1)\n",
    "    \n",
    "    training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "    valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c2daea-c071-4287-851d-6c85d942e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran for 4 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c313f4e-e1e5-4da8-ab29-1ee4edb2b593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.235743</td>\n",
       "      <td>1961.941047</td>\n",
       "      <td>26.848475</td>\n",
       "      <td>0.380559</td>\n",
       "      <td>-0.058643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.520917</td>\n",
       "      <td>1989.093115</td>\n",
       "      <td>27.006438</td>\n",
       "      <td>0.378166</td>\n",
       "      <td>-0.074763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.519243</td>\n",
       "      <td>1988.315226</td>\n",
       "      <td>27.012571</td>\n",
       "      <td>0.377802</td>\n",
       "      <td>-0.074900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.457351</td>\n",
       "      <td>1980.425124</td>\n",
       "      <td>26.977576</td>\n",
       "      <td>0.377315</td>\n",
       "      <td>-0.072714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.404562</td>\n",
       "      <td>1973.955446</td>\n",
       "      <td>26.933172</td>\n",
       "      <td>0.376742</td>\n",
       "      <td>-0.070784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE          MSE        MAE      MAPE        R2\n",
       "1  40.235743  1961.941047  26.848475  0.380559 -0.058643\n",
       "2  40.520917  1989.093115  27.006438  0.378166 -0.074763\n",
       "3  40.519243  1988.315226  27.012571  0.377802 -0.074900\n",
       "4  40.457351  1980.425124  26.977576  0.377315 -0.072714\n",
       "5  40.404562  1973.955446  26.933172  0.376742 -0.070784"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(valdiation_metrics_dicts)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67649f2f-b23f-468a-9fe2-16d0bfea3914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.093107</td>\n",
       "      <td>2573.902607</td>\n",
       "      <td>26.308632</td>\n",
       "      <td>0.363172</td>\n",
       "      <td>0.029911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.938249</td>\n",
       "      <td>2549.377139</td>\n",
       "      <td>26.090998</td>\n",
       "      <td>0.352865</td>\n",
       "      <td>0.033562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.903581</td>\n",
       "      <td>2545.377564</td>\n",
       "      <td>26.035516</td>\n",
       "      <td>0.351487</td>\n",
       "      <td>0.034607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.897975</td>\n",
       "      <td>2545.142854</td>\n",
       "      <td>25.992958</td>\n",
       "      <td>0.350677</td>\n",
       "      <td>0.034622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48.907055</td>\n",
       "      <td>2546.110784</td>\n",
       "      <td>25.961450</td>\n",
       "      <td>0.350150</td>\n",
       "      <td>0.034339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE          MSE        MAE      MAPE        R2\n",
       "1  49.093107  2573.902607  26.308632  0.363172  0.029911\n",
       "2  48.938249  2549.377139  26.090998  0.352865  0.033562\n",
       "3  48.903581  2545.377564  26.035516  0.351487  0.034607\n",
       "4  48.897975  2545.142854  25.992958  0.350677  0.034622\n",
       "5  48.907055  2546.110784  25.961450  0.350150  0.034339"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(training_metrics_dicts)/4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
