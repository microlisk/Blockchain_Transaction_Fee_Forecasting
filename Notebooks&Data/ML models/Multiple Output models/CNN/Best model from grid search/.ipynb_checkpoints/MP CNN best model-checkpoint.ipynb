{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed254beb-b30d-40dd-b1ab-1675290adaa0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb5ad5-6ded-42f0-882e-8d561521231c",
   "metadata": {},
   "source": [
    "Lets test the best model from the 1 month grid search on the full data, with and without MP for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cf8a4-056b-49a8-8123-cc15d8f2f71b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2243fdcb-c389-4556-be27-9373234fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras import callbacks\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, MaxPooling1D, AveragePooling1D,  GlobalMaxPooling1D, Flatten, Bidirectional, Input, Flatten, Activation, Reshape, RepeatVector, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pywt\n",
    "import matrixprofile as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7eee058-7ceb-4541-b2b4-2b9426ee3aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', 'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/HostX64/x64/cl.exe'), ('cuda_compute_capabilities', ['sm_35', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']), ('cuda_version', '64_112'), ('cudart_dll_name', 'cudart64_112.dll'), ('cudnn_dll_name', 'cudnn64_8.dll'), ('cudnn_version', '64_8'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False), ('msvcp_dll_names', 'msvcp140.dll,msvcp140_1.dll'), ('nvcuda_dll_name', 'nvcuda.dll')])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.python.platform.build_info as build\n",
    "print(build.build_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd68e3ae-22e3-43af-b5e2-abdca3c87420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead):\n",
    "    X, y = list(), list()\n",
    "    example_count = int((len(sequence)/step_interval))\n",
    "    for i in range(example_count):\n",
    "        # find the end of this pattern\n",
    "        end_ix = (i*step_interval) + n_steps_in\n",
    "        out_start_ix = end_ix + n_step_lookahead -1\n",
    "        out_end_ix = end_ix + n_steps_out + n_step_lookahead -1\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[(i*step_interval):end_ix], sequence[out_start_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479cb03e-33f8-4df8-afe6-82b2351713ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6],\n",
       "        [3, 4, 5, 6, 7]]),\n",
       " array([[ 9],\n",
       "        [10],\n",
       "        [11],\n",
       "        [12]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To demonstrate above function\n",
    "sequence = range(0,13)\n",
    "n_steps_in = 1\n",
    "n_steps_in = 5\n",
    "n_steps_out =1\n",
    "step_interval =1\n",
    "n_step_lookahead=5\n",
    "split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e0113c1-d102-4605-9fc3-542f00bd488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_data = pd.read_csv (r'C:\\Users/conal/Desktop/MCM/Practicum - Copy/data/block gas price percentile data.csv', header=0)\n",
    "percentile_data['datetime'] = pd.to_datetime(percentile_data['block_timestamp'], format = '%Y-%m-%d %H:%M:%S UTC')\n",
    "\n",
    "percentile_data = percentile_data.sort_values(by='datetime',ascending=False)\n",
    "percentile_data = percentile_data.set_index('datetime')\n",
    "percentile_data = percentile_data.resample('5T').mean()\n",
    "percentile_data = percentile_data/1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a6b649-6d02-4b5c-8892-6ca97fa10813",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum - Copy\\data\\ETH,gas,usage merged 11-26 to 05-26.csv', header=0)\n",
    "usage_data['datetime'] = pd.to_datetime(usage_data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "usage_data = usage_data.set_index('datetime')\n",
    "\n",
    "usage_data = usage_data.squeeze()\n",
    "usage_data = usage_data.astype('float')\n",
    "usage_data = usage_data.resample('5T').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49359adb-72a2-4d36-92a3-160ae229ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_data2 = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum - Copy\\data\\Contract counts 2021-11-26 to 2022-05-26.csv', header=0, index_col=0)\n",
    "usage_data2['datetime'] = pd.to_datetime(usage_data2['block_timestamp'], format = '%Y-%m-%d %H:%M:%S') \n",
    "usage_data2 = usage_data2.set_index('datetime')\n",
    "usage_data2 = usage_data2.drop(['block_timestamp'], axis=1)\n",
    "usage_data2 = usage_data2.squeeze()\n",
    "usage_data2 = usage_data2.astype('float')\n",
    "usage_data2 = usage_data2.resample('5T').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8901dad6-24e3-4393-bce8-03d4ff7aa1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = usage_data.merge(percentile_data, left_index=True, right_index=True)\n",
    "data = data.merge(usage_data2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123a9bf",
   "metadata": {},
   "source": [
    "Load data, datetime to index, downsample with left edge label, convert wei to gwei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac449a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples(data):\n",
    " \n",
    "    #Filter inputs, standardize\n",
    "    data =data[inputs]\n",
    "    scaler = StandardScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    \n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], len(inputs)))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], len(inputs)))\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046086f6-7346-4550-8d58-ba108d69ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "    \n",
    "    checkpoint_filepath='./cnn/checkpoint'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=9, activation='tanh', input_shape=(n_steps_in, len(inputs))))\n",
    "    model.add(Conv1D(filters=64, kernel_size=11, activation='tanh'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    model.add(LSTM(200, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='tanh')))\n",
    "    model.add(TimeDistributed(Dense(len(inputs))))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model, model_checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5878928-c13c-4766-bcfe-2a6d1de3a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1251aaea-8a1b-423a-80c4-d88e601b2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics(yhat, y_val2):\n",
    "    #reverts standard scaling, returns dictionary of metrics for each output, for all lookaheads\n",
    "    dict_indexes=[]\n",
    "    dict_dfs=[]\n",
    "    for j in range(0, n_steps_out):\n",
    "        RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "        for i in range(0, len(inputs)):  \n",
    "            pred_descaled= (scaler.inverse_transform(yhat[:,j:j+1,:].reshape(yhat.shape[0], yhat.shape[2])))[:, i:i+1]\n",
    "            groud_truth_descaled= ((scaler.inverse_transform(y_val2[:,j:j+1,:].reshape(y_val2.shape[0], y_val2.shape[2]))))[:, i:i+1]\n",
    "            RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "            MSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=True)\n",
    "            MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "            MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "            R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "            RMSE_list.append(RMSE)\n",
    "            MAE_list.append(MAE)\n",
    "            MAPE_list.append(MAPE)\n",
    "            R2_list.append(R2)\n",
    "            MSE_list.append(MSE)\n",
    "        metrics_df = pd.DataFrame({'RMSE':RMSE_list, 'MSE':MSE_list, 'MAE':MAE_list, 'MAPE':MAPE_list, 'R2':R2_list}, index=inputs)\n",
    "        dict_dfs.append(metrics_df)\n",
    "        dict_indexes.append('Lookahead' +str(j))\n",
    "    metrics_dict = dict(zip(dict_indexes, dict_dfs))\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e872e19c-41fd-4aa1-a3c0-bf9598fbd365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples_univariate_output(data):\n",
    " \n",
    "    #Filter inputs, standardize\n",
    "    data =data[inputs]\n",
    "    scaler = StandardScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    \n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    \n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM, filter output to only the first input\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], len(inputs)))[:,:,:1]\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], len(inputs)))[:,:,:1]\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b17abc08-deb1-47a6-8352-8f2b2f1a0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics_univariate_y(yhat, y_val2):\n",
    "    #reverts standard scaling, returns dictionary of metrics for single output, for all lookaheads\n",
    "    dict_indexes=[]\n",
    "    dict_dfs=[]\n",
    "    RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "    for j in range(0, n_steps_out):\n",
    "        pred_descaled= (scaler.inverse_transform(yhat[:, j:j+1, :len(inputs)].reshape(yhat.shape[0], len(inputs))))[:,:1]\n",
    "        groud_truth_descaled= (scaler.inverse_transform(array([y_val2[ :, j:j+1,0].reshape(y_val2.shape[0])]*len(inputs)).transpose()))[:,:1]\n",
    "        RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "        MSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=True)\n",
    "        MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "        MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "        R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "        RMSE_list.append(RMSE)\n",
    "        MAE_list.append(MAE)\n",
    "        MAPE_list.append(MAPE)\n",
    "        R2_list.append(R2)\n",
    "        MSE_list.append(MSE)\n",
    "    metrics_df = pd.DataFrame({'RMSE':RMSE_list, 'MSE':MSE_list, 'MAE':MAE_list, 'MAPE':MAPE_list, 'R2':R2_list}, index=range(1, (n_steps_out+1)))\n",
    "\n",
    " \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938fae8-5593-4505-8256-40ee5c792302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mp(data, window):\n",
    "    #Given 3d array, add matrix profile of (x,y,0) as new dimension; new array has dimensiosn (x,y,z+1) \n",
    "    mp_list=[]\n",
    "    for i in data[:,:,0]:\n",
    "        profile = mp.compute(i, window, n_jobs=4)['mp']\n",
    "        #we are padding the end of the sequence with the mean\n",
    "        #matrix profile is always 1 full window size smalelr than input data\n",
    "        mp_list.append(np.append(([mean(profile)]*(data.shape[1]-len(profile))),profile))\n",
    "        \n",
    "    #concatenate matrix profile data with original    \n",
    "    mp_array = np.array(mp_list).reshape(data.shape[0], data.shape[1])\n",
    "    std_array = ((mp_array-mean(mp_array))/np.std(mp_array)).reshape(data.shape[0], data.shape[1],1)\n",
    "    data = np.concatenate((data, std_array), axis=2)[:, window:, :]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c58089-df62-4980-83c6-af7767f54924",
   "metadata": {},
   "source": [
    "## Extend Lookahead to 10 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8823a41b-3569-4e9a-a3af-01bccd4338fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(filters, kernel_size):\n",
    "    checkpoint_filepath='./cnn/'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    input_layer = Input(shape=(n_steps_in, X_train.shape[2])) \n",
    "    head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        conv_layer_head = Conv1D(filters=filters, kernel_size=kernel_size, activation='tanh')(input_layer)\n",
    "        conv_layer_head_2 = Conv1D(filters=filters, kernel_size=kernel_size, activation='tanh')(conv_layer_head)\n",
    "        conv_layer_flatten = Flatten()(conv_layer_head_2)\n",
    "        head_list.append(conv_layer_flatten)\n",
    "\n",
    "    concat_cnn = Concatenate(axis=1)(head_list)\n",
    "    reshape = Reshape((head_list[0].shape[1], X_train.shape[2]))(concat_cnn)\n",
    "    lstm = LSTM(100, activation='tanh')(reshape)\n",
    "    repeat = RepeatVector(n_steps_out)(lstm)\n",
    "    lstm_2 = (Bidirectional(LSTM(100, activation='tanh', return_sequences=True)))(repeat)\n",
    "    dropout = Dropout(0.2)(lstm_2)\n",
    "    dense = Dense(X_train.shape[2], activation='linear')(dropout)\n",
    "    model = Model(inputs=input_layer, outputs=dense)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model, model_checkpoint_callback, checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "943b8451-213b-4868-9be6-3955b4c0234c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 136s 1s/step - loss: 0.2596 - val_loss: 0.0556\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.2346 - val_loss: 0.0582\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.2300 - val_loss: 0.0531\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.2201 - val_loss: 0.0587\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.2143 - val_loss: 0.0563\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.2073 - val_loss: 0.0596\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.2054 - val_loss: 0.0736\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.2008 - val_loss: 0.0574\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1941 - val_loss: 0.0645\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1879 - val_loss: 0.0635\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1904 - val_loss: 0.0591\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1856 - val_loss: 0.0588\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 124s 1s/step - loss: 0.1857 - val_loss: 0.0569\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 121s 1s/step - loss: 0.1810 - val_loss: 0.0584\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 118s 1s/step - loss: 0.1846 - val_loss: 0.0558\n",
      "101/101 [==============================] - 43s 409ms/step\n",
      "44/44 [==============================] - 18s 412ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/107 [==============================] - 135s 1s/step - loss: 0.7192 - val_loss: 0.4964\n",
      "Epoch 2/15\n",
      "107/107 [==============================] - 125s 1s/step - loss: 0.6020 - val_loss: 0.4330\n",
      "Epoch 3/15\n",
      "107/107 [==============================] - 126s 1s/step - loss: 0.5718 - val_loss: 0.4483\n",
      "Epoch 4/15\n",
      "107/107 [==============================] - 125s 1s/step - loss: 0.5642 - val_loss: 0.4442\n",
      "Epoch 5/15\n",
      "107/107 [==============================] - 125s 1s/step - loss: 0.5499 - val_loss: 0.4452\n",
      "Epoch 6/15\n",
      "107/107 [==============================] - 123s 1s/step - loss: 0.5475 - val_loss: 0.4604\n",
      "Epoch 7/15\n",
      "107/107 [==============================] - 125s 1s/step - loss: 0.5361 - val_loss: 0.4201\n",
      "Epoch 8/15\n",
      "107/107 [==============================] - 125s 1s/step - loss: 0.5336 - val_loss: 0.4468\n",
      "Epoch 9/15\n",
      "107/107 [==============================] - 125s 1s/step - loss: 0.5257 - val_loss: 0.4287\n",
      "Epoch 10/15\n",
      "107/107 [==============================] - 125s 1s/step - loss: 0.5244 - val_loss: 0.4491\n",
      "Epoch 11/15\n",
      "107/107 [==============================] - 124s 1s/step - loss: 0.4931 - val_loss: 0.4257\n",
      "Epoch 12/15\n",
      "107/107 [==============================] - 123s 1s/step - loss: 0.4779 - val_loss: 0.4347\n",
      "Epoch 13/15\n",
      "107/107 [==============================] - 122s 1s/step - loss: 0.4543 - val_loss: 0.4379\n",
      "Epoch 14/15\n",
      "107/107 [==============================] - 123s 1s/step - loss: 0.4336 - val_loss: 0.4622\n",
      "Epoch 15/15\n",
      "107/107 [==============================] - 122s 1s/step - loss: 0.4560 - val_loss: 0.4610\n",
      "107/107 [==============================] - 44s 398ms/step\n",
      "46/46 [==============================] - 18s 401ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 126s 1s/step - loss: 0.1829 - val_loss: 0.3743\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 116s 1s/step - loss: 0.1576 - val_loss: 0.3785\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 116s 1s/step - loss: 0.1510 - val_loss: 0.3662\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.1458 - val_loss: 0.3675\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.1407 - val_loss: 0.3622\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 114s 1s/step - loss: 0.1393 - val_loss: 0.3674\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.1294 - val_loss: 0.3973\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.1366 - val_loss: 0.3582\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.1278 - val_loss: 0.3757\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.1179 - val_loss: 0.3739\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.1134 - val_loss: 0.3765\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.1209 - val_loss: 0.3686\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 116s 1s/step - loss: 0.1097 - val_loss: 0.3583\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 119s 1s/step - loss: 0.1174 - val_loss: 0.3699\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 116s 1s/step - loss: 0.1125 - val_loss: 0.3711\n",
      "101/101 [==============================] - 42s 399ms/step\n",
      "44/44 [==============================] - 18s 413ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "82/82 [==============================] - 106s 1s/step - loss: 0.2246 - val_loss: 0.0484\n",
      "Epoch 2/15\n",
      "82/82 [==============================] - 94s 1s/step - loss: 0.1779 - val_loss: 0.0487\n",
      "Epoch 3/15\n",
      "82/82 [==============================] - 95s 1s/step - loss: 0.1688 - val_loss: 0.0428\n",
      "Epoch 4/15\n",
      "82/82 [==============================] - 99s 1s/step - loss: 0.1662 - val_loss: 0.0465\n",
      "Epoch 5/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1593 - val_loss: 0.0474\n",
      "Epoch 6/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1548 - val_loss: 0.0595\n",
      "Epoch 7/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1530 - val_loss: 0.0653\n",
      "Epoch 8/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1465 - val_loss: 0.0552\n",
      "Epoch 9/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1417 - val_loss: 0.0751\n",
      "Epoch 10/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1369 - val_loss: 0.0530\n",
      "Epoch 11/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1404 - val_loss: 0.0654\n",
      "Epoch 12/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1337 - val_loss: 0.0756\n",
      "Epoch 13/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1295 - val_loss: 0.0968\n",
      "Epoch 14/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1301 - val_loss: 0.1246\n",
      "Epoch 15/15\n",
      "82/82 [==============================] - 96s 1s/step - loss: 0.1341 - val_loss: 0.1143\n",
      "82/82 [==============================] - 36s 408ms/step\n",
      "36/36 [==============================] - 15s 407ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 129s 1s/step - loss: 0.1305 - val_loss: 0.0464\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 117s 1s/step - loss: 0.0920 - val_loss: 0.0461\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 116s 1s/step - loss: 0.0857 - val_loss: 0.0476\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 119s 1s/step - loss: 0.0730 - val_loss: 0.0461\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 118s 1s/step - loss: 0.0631 - val_loss: 0.0501\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 117s 1s/step - loss: 0.0605 - val_loss: 0.0458\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 116s 1s/step - loss: 0.0571 - val_loss: 0.0439\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 117s 1s/step - loss: 0.0627 - val_loss: 0.0434\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.0616 - val_loss: 0.0485\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 116s 1s/step - loss: 0.0519 - val_loss: 0.0471\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 116s 1s/step - loss: 0.0512 - val_loss: 0.0460\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.0514 - val_loss: 0.0573\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.0514 - val_loss: 0.0439\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.0503 - val_loss: 0.0594\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 115s 1s/step - loss: 0.0523 - val_loss: 0.0450\n",
      "101/101 [==============================] - 42s 400ms/step\n",
      "44/44 [==============================] - 18s 398ms/step\n"
     ]
    }
   ],
   "source": [
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032+288\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window = 288\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "parameter_index=[]\n",
    "month=0\n",
    "for filters in [9]:\n",
    "    for kernel_size in [7]:\n",
    "            for month in [0, 1, 2, 3, 4]:\n",
    "                n_steps_in = 4032+288\n",
    "                n_step_lookahead = 1\n",
    "                start_date=Start_dates[month]\n",
    "                end_date=end_dates[month]\n",
    "                X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "                X_train = add_mp(X_train, mp_window)\n",
    "                X_val = add_mp(X_val, mp_window)\n",
    "                n_steps_in = 4032\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                model, model_checkpoint_callback, checkpoint_filepath = LSTM_model(filters, kernel_size)\n",
    "                train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "                train_loss_list.append(train_history.history['loss'])\n",
    "                val_loss_list.append(train_history.history['val_loss'])\n",
    "\n",
    "                model.load_weights(checkpoint_filepath)\n",
    "                yhat_train=model.predict(X_train, verbose=1)\n",
    "                yhat_val = model.predict(X_val, verbose=1)\n",
    "                model.save_weights('mp_cnn_best_10lookahead/' +str(month)+'/')\n",
    "\n",
    "                training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "                valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "                np.save(\"mp_cnn_best_10lookahead/training_metrics.npy\", training_metrics_dicts)\n",
    "                np.save(\"mp_cnn_best_10lookahead/val_metrics.npy\", valdiation_metrics_dicts)\n",
    "\n",
    "                parameter_index.append([filters, kernel_size])\n",
    "\n",
    "                keras.backend.clear_session()\n",
    "\n",
    "                pd.DataFrame(train_loss_list).to_csv('mp_cnn_best_10lookahead/train_loss')\n",
    "                pd.DataFrame(val_loss_list).to_csv('mp_cnn_best_10lookahead/val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15e5e6e0-6e28-4aa3-b76f-51e762660a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         RMSE         MSE        MAE      MAPE        R2\n",
       " 1   14.399236  207.338004   9.984202  0.153011  0.625049\n",
       " 2   15.459951  239.010081  10.330912  0.152429  0.567725\n",
       " 3   16.075388  258.418090  10.736479  0.155109  0.532628\n",
       " 4   16.707183  279.129976  11.069232  0.158046  0.495104\n",
       " 5   17.009718  289.330490  11.249533  0.159771  0.476587\n",
       " 6   17.413791  303.240107  11.594301  0.165363  0.451313\n",
       " 7   17.636058  311.030551  11.938548  0.172115  0.437213\n",
       " 8   17.741563  314.763068  12.194381  0.177828  0.430208\n",
       " 9   17.921318  321.173654  12.550755  0.186349  0.419034\n",
       " 10  18.210865  331.635598  13.156697  0.199449  0.400502,\n",
       "          RMSE          MSE        MAE      MAPE        R2\n",
       " 1   42.071518  1770.012613  26.903243  0.193842  0.544768\n",
       " 2   44.878347  2014.066021  28.782214  0.206614  0.481117\n",
       " 3   46.200776  2134.511733  29.726407  0.212939  0.449250\n",
       " 4   46.994716  2208.503334  30.038223  0.213533  0.429571\n",
       " 5   47.522918  2258.427718  30.224780  0.213359  0.416672\n",
       " 6   48.148669  2318.294373  30.334229  0.212349  0.401190\n",
       " 7   48.767999  2378.317723  30.528670  0.212098  0.385021\n",
       " 8   49.482098  2448.478042  30.599964  0.210326  0.366275\n",
       " 9   49.953274  2495.329544  30.763510  0.208927  0.351738\n",
       " 10  50.223591  2522.409060  30.697530  0.205702  0.341479,\n",
       "          RMSE          MSE        MAE      MAPE        R2\n",
       " 1   41.888551  1754.650715  18.229595  0.258885  0.318047\n",
       " 2   42.531465  1808.925504  18.377403  0.253332  0.296950\n",
       " 3   42.988362  1847.999264  18.596011  0.252256  0.281854\n",
       " 4   43.345169  1878.803699  19.166005  0.258156  0.270025\n",
       " 5   43.724426  1911.825452  19.471362  0.262326  0.257511\n",
       " 6   44.084626  1943.454292  19.821819  0.268170  0.245475\n",
       " 7   44.487360  1979.125237  20.378038  0.277930  0.231819\n",
       " 8   44.883145  2014.496697  20.872347  0.288365  0.218150\n",
       " 9   45.120895  2035.895176  21.531604  0.303875  0.209972\n",
       " 10  45.314068  2053.364739  22.146817  0.321361  0.203431,\n",
       "          RMSE         MSE        MAE      MAPE        R2\n",
       " 1   13.541960  183.384694  10.068076  0.278836  0.554976\n",
       " 2   13.962504  194.951532   9.714058  0.250179  0.527280\n",
       " 3   14.679486  215.487305   9.858203  0.244658  0.477829\n",
       " 4   14.913414  222.409913   9.970878  0.243530  0.461466\n",
       " 5   15.294974  233.936219  10.281763  0.251176  0.433857\n",
       " 6   15.321602  234.751477  10.393115  0.256674  0.432312\n",
       " 7   15.602647  243.442603  10.654597  0.267082  0.411842\n",
       " 8   15.792589  249.405856  10.923304  0.278998  0.397881\n",
       " 9   16.087030  258.792541  11.285901  0.293212  0.375592\n",
       " 10  16.263134  264.489529  11.607745  0.306522  0.362256,\n",
       "          RMSE         MSE        MAE      MAPE        R2\n",
       " 1   12.674734  160.648883   8.191778  0.209967  0.633352\n",
       " 2   13.609771  185.225870   8.741719  0.216987  0.577390\n",
       " 3   14.155552  200.379661   9.134254  0.225847  0.542961\n",
       " 4   14.561198  212.028486   9.479101  0.236192  0.516398\n",
       " 5   14.822061  219.693482   9.823374  0.248552  0.498916\n",
       " 6   15.223827  231.764924  10.273197  0.264788  0.471786\n",
       " 7   15.649191  244.897179  10.859809  0.284700  0.442091\n",
       " 8   16.202834  262.531816  11.612812  0.309984  0.402228\n",
       " 9   16.856102  284.128186  12.533329  0.342016  0.354057\n",
       " 10  17.716208  313.864035  13.737756  0.385319  0.289102]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdiation_metrics_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152aec0-8204-446e-b4fa-42900c369b41",
   "metadata": {},
   "source": [
    "## No MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb03e779-13d6-465b-91cb-2c25a783babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(filters, kernel_size):\n",
    "    checkpoint_filepath='./cnn/'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    input_layer = Input(shape=(n_steps_in, X_train.shape[2])) \n",
    "    head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        conv_layer_head = Conv1D(filters=filters, kernel_size=kernel_size, activation='tanh')(input_layer)\n",
    "        conv_layer_head_2 = Conv1D(filters=filters, kernel_size=kernel_size, activation='tanh')(conv_layer_head)\n",
    "        conv_layer_flatten = Flatten()(conv_layer_head_2)\n",
    "        head_list.append(conv_layer_flatten)\n",
    "\n",
    "    concat_cnn = Concatenate(axis=1)(head_list)\n",
    "    reshape = Reshape((head_list[0].shape[1], X_train.shape[2]))(concat_cnn)\n",
    "    lstm = LSTM(100, activation='tanh')(reshape)\n",
    "    repeat = RepeatVector(n_steps_out)(lstm)\n",
    "    lstm_2 = (Bidirectional(LSTM(100, activation='tanh', return_sequences=True)))(repeat)\n",
    "    dropout = Dropout(0.2)(lstm_2)\n",
    "    dense = Dense(X_train.shape[2], activation='linear')(dropout)\n",
    "    model = Model(inputs=input_layer, outputs=dense)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model, model_checkpoint_callback, checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "085ae562-429e-4005-82d1-d96c6643b469",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "114/114 [==============================] - 141s 1s/step - loss: 0.7192 - val_loss: 0.5077\n",
      "Epoch 2/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.5864 - val_loss: 0.4189\n",
      "Epoch 3/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.5595 - val_loss: 0.4430\n",
      "Epoch 4/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.5447 - val_loss: 0.3962\n",
      "Epoch 5/15\n",
      "114/114 [==============================] - 131s 1s/step - loss: 0.5380 - val_loss: 0.6076\n",
      "Epoch 6/15\n",
      "114/114 [==============================] - 132s 1s/step - loss: 0.5119 - val_loss: 0.5784\n",
      "Epoch 7/15\n",
      "114/114 [==============================] - 128s 1s/step - loss: 0.4953 - val_loss: 0.4004\n",
      "Epoch 8/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.4599 - val_loss: 0.4639\n",
      "Epoch 9/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.4418 - val_loss: 0.4194\n",
      "Epoch 10/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.4299 - val_loss: 0.4519\n",
      "Epoch 11/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.4230 - val_loss: 0.4482\n",
      "Epoch 12/15\n",
      "114/114 [==============================] - 128s 1s/step - loss: 0.3821 - val_loss: 0.4405\n",
      "Epoch 13/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.3789 - val_loss: 0.4946\n",
      "Epoch 14/15\n",
      "114/114 [==============================] - 131s 1s/step - loss: 0.3494 - val_loss: 0.5425\n",
      "Epoch 15/15\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.3500 - val_loss: 0.5015\n",
      "114/114 [==============================] - 47s 393ms/step\n",
      "49/49 [==============================] - 19s 391ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/107 [==============================] - 132s 1s/step - loss: 0.2728 - val_loss: 0.3509\n",
      "Epoch 2/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.2451 - val_loss: 0.3560\n",
      "Epoch 3/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.2394 - val_loss: 0.3400\n",
      "Epoch 4/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.2284 - val_loss: 0.3473\n",
      "Epoch 5/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.2211 - val_loss: 0.3472\n",
      "Epoch 6/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.2067 - val_loss: 0.3536\n",
      "Epoch 7/15\n",
      "107/107 [==============================] - 122s 1s/step - loss: 0.1964 - val_loss: 0.3513\n",
      "Epoch 8/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.2017 - val_loss: 0.3439\n",
      "Epoch 9/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.1818 - val_loss: 0.3471\n",
      "Epoch 10/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.1808 - val_loss: 0.3512\n",
      "Epoch 11/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.1837 - val_loss: 0.3786\n",
      "Epoch 12/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.1819 - val_loss: 0.3618\n",
      "Epoch 13/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.1668 - val_loss: 0.3511\n",
      "Epoch 14/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.1672 - val_loss: 0.3509\n",
      "Epoch 15/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.1646 - val_loss: 0.3523\n",
      "107/107 [==============================] - 44s 389ms/step\n",
      "46/46 [==============================] - 18s 389ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "88/88 [==============================] - 106s 1s/step - loss: 0.2252 - val_loss: 0.0499\n",
      "Epoch 2/15\n",
      "88/88 [==============================] - 100s 1s/step - loss: 0.1870 - val_loss: 0.0416\n",
      "Epoch 3/15\n",
      "88/88 [==============================] - 101s 1s/step - loss: 0.1788 - val_loss: 0.0442\n",
      "Epoch 4/15\n",
      "88/88 [==============================] - 100s 1s/step - loss: 0.1755 - val_loss: 0.0450\n",
      "Epoch 5/15\n",
      "88/88 [==============================] - 100s 1s/step - loss: 0.1657 - val_loss: 0.0667\n",
      "Epoch 6/15\n",
      "88/88 [==============================] - 100s 1s/step - loss: 0.1611 - val_loss: 0.0676\n",
      "Epoch 7/15\n",
      "88/88 [==============================] - 104s 1s/step - loss: 0.1522 - val_loss: 0.0415\n",
      "Epoch 8/15\n",
      "88/88 [==============================] - 102s 1s/step - loss: 0.1449 - val_loss: 0.0924\n",
      "Epoch 9/15\n",
      "88/88 [==============================] - 99s 1s/step - loss: 0.1460 - val_loss: 0.0434\n",
      "Epoch 10/15\n",
      "88/88 [==============================] - 98s 1s/step - loss: 0.1422 - val_loss: 0.0411\n",
      "Epoch 11/15\n",
      "88/88 [==============================] - 98s 1s/step - loss: 0.1353 - val_loss: 0.0428\n",
      "Epoch 12/15\n",
      "88/88 [==============================] - 99s 1s/step - loss: 0.1543 - val_loss: 0.0447\n",
      "Epoch 13/15\n",
      "88/88 [==============================] - 106s 1s/step - loss: 0.1398 - val_loss: 0.0608\n",
      "Epoch 14/15\n",
      "88/88 [==============================] - 98s 1s/step - loss: 0.1290 - val_loss: 0.0418\n",
      "Epoch 15/15\n",
      "88/88 [==============================] - 98s 1s/step - loss: 0.1298 - val_loss: 0.0564\n",
      "88/88 [==============================] - 36s 388ms/step\n",
      "38/38 [==============================] - 16s 390ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/107 [==============================] - 131s 1s/step - loss: 0.1216 - val_loss: 0.0515\n",
      "Epoch 2/15\n",
      "107/107 [==============================] - 121s 1s/step - loss: 0.0867 - val_loss: 0.0486\n",
      "Epoch 3/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.0768 - val_loss: 0.0428\n",
      "Epoch 4/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.0743 - val_loss: 0.0508\n",
      "Epoch 5/15\n",
      "107/107 [==============================] - 121s 1s/step - loss: 0.0675 - val_loss: 0.0466\n",
      "Epoch 6/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.0639 - val_loss: 0.0417\n",
      "Epoch 7/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.0560 - val_loss: 0.0431\n",
      "Epoch 8/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.0545 - val_loss: 0.0429\n",
      "Epoch 9/15\n",
      "107/107 [==============================] - 121s 1s/step - loss: 0.0573 - val_loss: 0.0560\n",
      "Epoch 10/15\n",
      "107/107 [==============================] - 122s 1s/step - loss: 0.0576 - val_loss: 0.0638\n",
      "Epoch 11/15\n",
      "107/107 [==============================] - 121s 1s/step - loss: 0.0499 - val_loss: 0.0647\n",
      "Epoch 12/15\n",
      "107/107 [==============================] - 121s 1s/step - loss: 0.0485 - val_loss: 0.0454\n",
      "Epoch 13/15\n",
      "107/107 [==============================] - 121s 1s/step - loss: 0.0455 - val_loss: 0.0533\n",
      "Epoch 14/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.0453 - val_loss: 0.0514\n",
      "Epoch 15/15\n",
      "107/107 [==============================] - 120s 1s/step - loss: 0.0446 - val_loss: 0.0572\n",
      "107/107 [==============================] - 43s 388ms/step\n",
      "46/46 [==============================] - 18s 389ms/step\n"
     ]
    }
   ],
   "source": [
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2021-12-26 23:55:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00', '2022-04-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00', '2021-12-26 00:00:00', '2022-01-26 23:55:00', '2022-02-26 23:55:00', '2022-03-26 23:55:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032\n",
    "n_steps_out = 10\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "parameter_index=[]\n",
    "month=0\n",
    "for filters in [9]:\n",
    "    for kernel_size in [7]:\n",
    "            for month in [0, 1, 2, 3, 4]:\n",
    "                n_steps_in = 4032\n",
    "                n_step_lookahead = 1\n",
    "                start_date=Start_dates[month]\n",
    "                end_date=end_dates[month]\n",
    "                X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                model, model_checkpoint_callback, checkpoint_filepath = LSTM_model(filters, kernel_size)\n",
    "                train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "                train_loss_list.append(train_history.history['loss'])\n",
    "                val_loss_list.append(train_history.history['val_loss'])\n",
    "\n",
    "                model.load_weights(checkpoint_filepath)\n",
    "                yhat_train=model.predict(X_train, verbose=1)\n",
    "                yhat_val = model.predict(X_val, verbose=1)\n",
    "                model.save_weights('cnn_best_10lookahead/' +str(month)+'/')\n",
    "\n",
    "                training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "                valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "                np.save(\"cnn_best_10lookahead/training_metrics.npy\", training_metrics_dicts)\n",
    "                np.save(\"cnn_best_10lookahead/val_metrics.npy\", valdiation_metrics_dicts)\n",
    "\n",
    "                parameter_index.append([filters, kernel_size])\n",
    "\n",
    "                keras.backend.clear_session()\n",
    "\n",
    "                pd.DataFrame(train_loss_list).to_csv('cnn_best_10lookahead/train_loss')\n",
    "                pd.DataFrame(val_loss_list).to_csv('cnn_best_10lookahead/val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d84b27f-1811-405a-8b09-40d0a2682341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         RMSE         MSE        MAE      MAPE        R2\n",
       " 1   17.156416  294.342598  12.293846  0.186768  0.485840\n",
       " 2   17.332388  300.411689  12.300291  0.183775  0.475217\n",
       " 3   17.534323  307.452499  12.347169  0.182476  0.462948\n",
       " 4   17.793027  316.591811  12.623060  0.185456  0.446830\n",
       " 5   18.022723  324.818541  12.846932  0.188649  0.432033\n",
       " 6   18.264434  333.589561  13.116082  0.193610  0.416443\n",
       " 7   18.438039  339.961294  13.434818  0.200742  0.405371\n",
       " 8   18.790016  353.064718  13.947682  0.211944  0.382604\n",
       " 9   19.298107  372.416946  14.674824  0.227697  0.349026\n",
       " 10  20.009536  400.381529  15.653866  0.248524  0.300454,\n",
       "          RMSE          MSE        MAE      MAPE        R2\n",
       " 1   39.871278  1589.718802  21.935246  0.137405  0.583111\n",
       " 2   42.194250  1780.354755  24.276039  0.155406  0.533239\n",
       " 3   43.686297  1908.492557  25.809123  0.167490  0.499568\n",
       " 4   45.051703  2029.655945  26.930740  0.175913  0.467908\n",
       " 5   46.081476  2123.502393  28.005436  0.183963  0.443462\n",
       " 6   46.911504  2200.689232  28.920812  0.190572  0.423717\n",
       " 7   47.854176  2290.022165  29.568924  0.194613  0.400245\n",
       " 8   48.640116  2365.860912  29.881616  0.195841  0.380545\n",
       " 9   49.191954  2419.848334  30.397760  0.197904  0.366212\n",
       " 10  49.598016  2459.963208  30.870740  0.198657  0.355653,\n",
       "          RMSE          MSE        MAE      MAPE        R2\n",
       " 1   39.178478  1534.953153  17.961472  0.256137  0.382450\n",
       " 2   40.237610  1619.065297  18.730476  0.259705  0.348611\n",
       " 3   41.138979  1692.415558  19.331226  0.265434  0.319186\n",
       " 4   42.067208  1769.649959  20.075923  0.275380  0.288366\n",
       " 5   42.739945  1826.702905  20.568901  0.283653  0.265693\n",
       " 6   43.249964  1870.559424  21.089675  0.293802  0.247974\n",
       " 7   43.812251  1919.513351  21.666234  0.307065  0.228370\n",
       " 8   44.147450  1948.997330  22.177099  0.322058  0.216259\n",
       " 9   44.700171  1998.105300  22.930208  0.344475  0.196354\n",
       " 10  45.472600  2067.757305  24.215074  0.378738  0.168540,\n",
       "          RMSE         MSE        MAE      MAPE        R2\n",
       " 1   12.862266  165.437899   9.116505  0.243189  0.580766\n",
       " 2   13.776078  189.780317   9.548741  0.244216  0.519609\n",
       " 3   14.505683  210.414830   9.884141  0.248012  0.467529\n",
       " 4   15.055156  226.657716  10.145820  0.252097  0.426713\n",
       " 5   15.306440  234.287102  10.345950  0.254958  0.407742\n",
       " 6   15.383993  236.667234  10.274651  0.252605  0.402210\n",
       " 7   15.452581  238.782245  10.347338  0.254355  0.397450\n",
       " 8   15.341619  235.365270  10.305119  0.255138  0.406545\n",
       " 9   15.156064  229.706284  10.223374  0.256117  0.420986\n",
       " 10  15.125217  228.772190  10.424965  0.268256  0.423307,\n",
       "          RMSE         MSE        MAE      MAPE        R2\n",
       " 1   12.802864  163.913337   8.389289  0.215671  0.632013\n",
       " 2   13.571041  184.173151   8.482278  0.201890  0.585548\n",
       " 3   14.083561  198.346686   8.589802  0.196086  0.552108\n",
       " 4   14.377962  206.725800   8.863905  0.198999  0.532114\n",
       " 5   14.736326  217.159311   8.983486  0.200466  0.507985\n",
       " 6   15.049288  226.481075   9.099174  0.202933  0.487004\n",
       " 7   15.417754  237.707135   9.350518  0.209270  0.461540\n",
       " 8   15.792038  249.388467   9.794648  0.223584  0.435001\n",
       " 9   16.131634  260.229610  10.353235  0.246506  0.411036\n",
       " 10  16.700443  278.904790  11.444868  0.289054  0.370464]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdiation_metrics_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8308ede1-dc0a-450e-9486-b0be201f2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cnn_best_10lookahead/training_metrics.npy\", training_metrics_dicts)\n",
    "np.save(\"cnn_best_10lookahead/val_metrics.npy\", valdiation_metrics_dicts)\n",
    "\n",
    "parameter_index.append([filters, kernel_size])\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "pd.DataFrame(val_loss_list).to_csv('cnn_best_10lookahead/val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921569d-0d78-4d4e-b3da-ea2a98db2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valdiation_metrics_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632777b7-d96d-450b-99a2-5f3c136476a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53a26eae-4928-493a-a772-c1cec94b9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(filters, kernel_size):\n",
    "    checkpoint_filepath='./cnn/'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    input_layer = Input(shape=(n_steps_in, X_train.shape[2])) \n",
    "    head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        conv_layer_head = Conv1D(filters=filters, kernel_size=kernel_size, activation='tanh')(input_layer)\n",
    "        conv_layer_head_2 = Conv1D(filters=filters, kernel_size=kernel_size, activation='tanh')(conv_layer_head)\n",
    "        conv_layer_flatten = Flatten()(conv_layer_head_2)\n",
    "        head_list.append(conv_layer_flatten)\n",
    "\n",
    "    concat_cnn = Concatenate(axis=1)(head_list)\n",
    "    reshape = Reshape((head_list[0].shape[1], X_train.shape[2]))(concat_cnn)\n",
    "    lstm = LSTM(100, activation='tanh')(reshape)\n",
    "    repeat = RepeatVector(n_steps_out)(lstm)\n",
    "    lstm_2 = (Bidirectional(LSTM(100, activation='tanh', return_sequences=True)))(repeat)\n",
    "    dropout = Dropout(0.2)(lstm_2)\n",
    "    dense = Dense(X_train.shape[2], activation='linear')(dropout)\n",
    "    model = Model(inputs=input_layer, outputs=dense)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model, model_checkpoint_callback, checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915d597-3442-4d7b-8429-85c2eccfec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mp_reversed(data, window):\n",
    "    #Given 3d array, add matrix profile of (x,y,0) as new dimension; new array has dimensiosn (x,y,z+1) \n",
    "    mp_list=[]\n",
    "    for i in data[:,:,0]:\n",
    "        profile = mp.compute(np.flip(i, axis=0), window, n_jobs=4)['mp']\n",
    "        #we are padding the end of the sequence with the mean\n",
    "        #matrix profile is always 1 full window size smalelr than input data\n",
    "        mp_list.append(np.append(profile,([mean(profile)]*(data.shape[1]-len(profile)))))\n",
    "        \n",
    "    #concatenate matrix profile data with original    \n",
    "    mp_array = np.array(mp_list).reshape(data.shape[0], data.shape[1])\n",
    "    std_array = ((mp_array-mean(mp_array))/np.std(mp_array)).reshape(data.shape[0], data.shape[1],1)\n",
    "    data = np.concatenate((data, std_array), axis=2)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a923bec-304a-4ec6-a42b-5eaa9e0e0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de845bcc-8884-42ba-9df9-ddf822e5cdc0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "498/498 [==============================] - ETA: 0s - loss: 0.4266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cnn\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BABD68AFA0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C186B453A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BAB55AD910> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 [==============================] - 246s 439ms/step - loss: 0.4266 - val_loss: 1.0778\n",
      "Epoch 2/15\n",
      " 29/498 [>.............................] - ETA: 2:18 - loss: 0.4889"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19468/291104957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mtrain_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                 \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mval_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "end_dates = ['2022-02-26 23:55:00'  ]\n",
    "Start_dates = ['2021-11-26 00:00:00']\n",
    "\n",
    "#end_dates = ['2022-01-26 23:55:00', '2022-03-26 23:55:00']\n",
    "#Start_dates = ['2021-11-26 00:00:00', '2022-01-26 00:00:00']\n",
    "inputs = ['min_gas_price', 'block_gas_5th_percentile', 'block_gas_95th_percentile', 'gas_used', 'base_fee_per_gas', 'transaction_count', 'size', 'Open', 'contracts']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 4032\n",
    "n_steps_out = 5\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1\n",
    "mp_window = 288\n",
    "\n",
    "\n",
    "y_hat_list=[]\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "training_metrics_dicts=[]\n",
    "valdiation_metrics_dicts=[]\n",
    "parameter_index=[]\n",
    "month=0\n",
    "for filters in [9]:\n",
    "    for kernel_size in [7]:\n",
    "            for month in [0]:\n",
    "                n_step_lookahead = 1\n",
    "                start_date=Start_dates[month]\n",
    "                end_date=end_dates[month]\n",
    "                X_train, y_train, X_val, y_val, scaler = generate_training_val_examples_univariate_output(data)\n",
    "                X_train = add_mp_reversed(X_train, mp_window)\n",
    "                X_val = add_mp_reversed(X_val, mp_window)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                model, model_checkpoint_callback, checkpoint_filepath = LSTM_model(filters, kernel_size)\n",
    "                train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])\n",
    "                train_loss_list.append(train_history.history['loss'])\n",
    "                val_loss_list.append(train_history.history['val_loss'])\n",
    "\n",
    "                model.load_weights(checkpoint_filepath)\n",
    "                yhat_train=model.predict(X_train, verbose=1)\n",
    "                yhat_val = model.predict(X_val, verbose=1)\n",
    "                model.save('mp_cnn_best2/' +str(month)+'/')\n",
    "\n",
    "                training_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_train, y_train))\n",
    "                valdiation_metrics_dicts.append(descale_y_retrun_metrics_univariate_y(yhat_val, y_val))\n",
    "                np.save(\"mp_cnn_best2/training_metrics.npy\", training_metrics_dicts)\n",
    "                np.save(\"mp_cnn_best2/val_metrics.npy\", valdiation_metrics_dicts)\n",
    "\n",
    "                parameter_index.append([filters, kernel_size])\n",
    "\n",
    "                keras.backend.clear_session()\n",
    "\n",
    "                pd.DataFrame(train_loss_list).to_csv('mp_cnn_best2/train_loss')\n",
    "                pd.DataFrame(val_loss_list).to_csv('mp_cnn_best2/val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e22faa6-fc58-4e7f-9865-73585f846185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(filters, kernel_size):\n",
    "    checkpoint_filepath='./cnn/'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    input_layer = Input(shape=(n_steps_in, X_train.shape[2])) \n",
    "    head_list = []\n",
    "    for i in range(0, X_train.shape[2]):\n",
    "        conv_layer_head = Conv1D(filters=filters, kernel_size=kernel_size, activation='tanh')(input_layer)\n",
    "        conv_layer_head_2 = Conv1D(filters=filters, kernel_size=kernel_size, activation='tanh')(conv_layer_head)\n",
    "       \n",
    "        pooled = AveragePooling1D(pool_size=4, strides=4)(conv_layer_head)\n",
    "        conv_layer_flatten = Flatten()(pooled)\n",
    "        head_list.append(conv_layer_flatten)\n",
    "\n",
    "    concat_cnn = Concatenate(axis=1)(head_list)\n",
    "    reshape = Reshape((head_list[0].shape[1], X_train.shape[2]))(concat_cnn)\n",
    "    lstm = LSTM(100, activation='tanh')(reshape)\n",
    "    repeat = RepeatVector(n_steps_out)(lstm)\n",
    "    lstm_2 = (Bidirectional(LSTM(100, activation='tanh', return_sequences=True)))(repeat)\n",
    "    dropout = Dropout(0.3)(lstm_2)\n",
    "    dense = Dense(X_train.shape[2], activation='linear')(dropout)\n",
    "    model = Model(inputs=input_layer, outputs=dense)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model, model_checkpoint_callback, checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e2968a2-4f67-4882-b5b1-9f81c18fb49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3652WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_40_layer_call_fn, lstm_cell_40_layer_call_and_return_conditional_losses, lstm_cell_42_layer_call_fn, lstm_cell_42_layer_call_and_return_conditional_losses, lstm_cell_43_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cnn\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C17D55DCD0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BABAE96FD0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001C1A6A4AF70> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 114s 1s/step - loss: 0.3652 - val_loss: 0.0706\n",
      "Epoch 2/15\n",
      "107/107 [==============================] - 35s 327ms/step - loss: 0.3341 - val_loss: 0.0809\n",
      "Epoch 3/15\n",
      "107/107 [==============================] - 35s 325ms/step - loss: 0.3243 - val_loss: 0.0862\n",
      "Epoch 4/15\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3139"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19468/1792388598.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1418\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1420\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1421\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, model_checkpoint_callback, checkpoint_filepath = LSTM_model(filters, kernel_size)\n",
    "train_history = model.fit(X_train, y_train,validation_data=(X_val, y_val), epochs=15, verbose=1, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de703f-e9eb-43d6-8e20-802a478d48d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
